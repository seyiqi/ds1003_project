{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ONLY ON MY COMPUTER\n",
    "import sys\n",
    "import sys,os,os.path\n",
    "python_path = ['', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python27.zip', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-darwin', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac/lib-scriptpackages', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-tk', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-old', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg', '/Users/Melancardie/Dropbox/Documents/My School/NYU/Spring 2017/DS-GA 1008/HW/hw3/ALI']\n",
    "\n",
    "for p in python_path:\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DATA LOADING FUNCTIONS\n",
    "\n",
    "# split dataset\n",
    "def split_dataset(full_data, train_ratio, validation_ratio, test_ratio):\n",
    "    \"\"\"\n",
    "    Function that splits the dataset into train, validation, and test\n",
    "    \"\"\"\n",
    "    random_idx = np.random.permutation(len(full_data))\n",
    "    train_threshold = int(round(train_ratio*len(full_data)))\n",
    "    validation_threshold = int(round((train_ratio+validation_ratio)*len(full_data)))\n",
    "    \n",
    "    train_set = full_data.iloc[random_idx[:train_threshold]]\n",
    "    validation_set = full_data.iloc[random_idx[train_threshold:validation_threshold]]\n",
    "    test_set = full_data.iloc[random_idx[validation_threshold:]]\n",
    "    \n",
    "    return train_set, validation_set, test_set\n",
    "\n",
    "\n",
    "# load dataset\n",
    "def load_datasets(load_dir = \"../data/kaggle_competition/\", prefix=\"clean_kaggle_\", post_fix=\"\"):\n",
    "    \"\"\"\n",
    "    Function that loads the dataset\n",
    "    \"\"\"\n",
    "    train_set = pd.read_csv(os.path.join(load_dir, \"{0}train{1}.csv\".format(prefix,post_fix)), keep_default_na=False)\n",
    "    validation_set = pd.read_csv(os.path.join(load_dir, \"{0}validation{1}.csv\".format(prefix,post_fix)), keep_default_na=False)\n",
    "    test_set = pd.read_csv(os.path.join(load_dir, \"{0}test{1}.csv\".format(prefix,post_fix)), keep_default_na=False)\n",
    "    return train_set, validation_set, test_set\n",
    "\n",
    "def xy_split(df, label_col=\"is_duplicate\"):\n",
    "    \"\"\"\n",
    "    Function that splits a data frame into X and y\n",
    "    \"\"\"\n",
    "    return df.drop(label_col, axis=1), df[label_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA CLEANING FUNCTIONS\n",
    "def clean_str(input_str):\n",
    "    \"\"\"\n",
    "    Helper function that converts string to ASCII\n",
    "    \"\"\"\n",
    "    # trivial case\n",
    "    if pd.isnull(input_str) or type(input_str)==np.float or type(input_str)==float:\n",
    "        return \"\"\n",
    "    # encoding\n",
    "    input_str = input_str.decode('ascii', 'ignore').lower()\n",
    "    # remove bad symbols\n",
    "    input_str = input_str.replace(\"\\n\",\"\")\n",
    "    return input_str\n",
    "\n",
    "def clean_dataset(full_dataset):\n",
    "    \"\"\"\n",
    "    Function that cleans the full dataset\n",
    "    \"\"\"\n",
    "    full_dataset[\"clean_q1\"] = full_dataset[\"question1\"].apply(clean_str,1)\n",
    "    full_dataset[\"clean_q2\"] = full_dataset[\"question2\"].apply(clean_str,1)\n",
    "    col_need = [\"clean_q1\", \"clean_q2\"]\n",
    "    if \"is_duplicate\" in full_dataset.columns:\n",
    "        col_need += [\"is_duplicate\"]\n",
    "    return full_dataset[col_need]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/Melancardie/Dropbox/Documents/My Research/NYU/Sundararajan/trust/lib/glove.6B/glove.6B.50d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e70191e64e82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mword_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mglove_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-e70191e64e82>\u001b[0m in \u001b[0;36mload_embedding\u001b[0;34m(glove_file, line_to_load)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mctr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mword_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/Melancardie/Dropbox/Documents/My Research/NYU/Sundararajan/trust/lib/glove.6B/glove.6B.50d.txt'"
     ]
    }
   ],
   "source": [
    "# FEATURE ENGINEERING FUNCTIONS\n",
    "def word_overlap(row):\n",
    "    \"\"\"\n",
    "    Function that calculates the percentage of word overlap\n",
    "    \"\"\"\n",
    "    avg_length = float(len(row['token_1'])+len(row['token_2']))/2\n",
    "    same_token_num = len(set(row['token_1']).intersection(set(row['token_2'])))\n",
    "    return float(same_token_num)/avg_length\n",
    "\n",
    "def overlap_no_stops(row,stops=stops):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in row['token_1']:\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in row['token_2']:\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    shared_words = [w for w in q1words.keys() if w in q2words]\n",
    "    return 2*(len(shared_words))/(len(q1words) + len(q2words))\n",
    "\n",
    "def sentence_similarity(row):\n",
    "    \"\"\"\n",
    "    Function that returns the Spacy sentence similarity\n",
    "    \"\"\"\n",
    "    return row[\"doc1\"].similarity(row[\"doc2\"])\n",
    "\n",
    "\n",
    "def jaccard_sim(set1, set2):\n",
    "    \"\"\"\n",
    "    Jaccard Similarity\n",
    "    \"\"\"\n",
    "    if len(set1.union(set2)) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(len(set1.intersection(set2)))/len(set1.union(set2))\n",
    "\n",
    "def jaccard_sim_unhashbale(set1, set2):\n",
    "    \"\"\"\n",
    "    Jaccard Similarity\n",
    "    \"\"\"\n",
    "    count = 0.0\n",
    "    str_set2 = str(set2)\n",
    "    for i in set1:\n",
    "        if str(i) in str_set2:\n",
    "            count += 1.0\n",
    "    if (len(set1)+len(set2)-count) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return count/ (len(set1)+len(set2)-count)\n",
    "    \n",
    "    \n",
    "def load_embedding(glove_file=\"/Users/Melancardie/Dropbox/Documents/My Research/NYU/Sundararajan/trust/lib/glove.6B/glove.6B.50d.txt\",\n",
    "                   line_to_load = 50000):\n",
    "    \"\"\"\n",
    "    Function that populates a dictionary with word embedding vectors\n",
    "    \"\"\"\n",
    "    ctr = 0\n",
    "    word_emb = {}\n",
    "    with open(glove_file, \"r\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            contents = line.split()\n",
    "            word_emb[contents[0]]=np.asarray(contents[1:]).astype(float)\n",
    "            ctr += 1\n",
    "            if ctr >= line_to_load:\n",
    "                break\n",
    "    return word_emb\n",
    "glove_emb = load_embedding()\n",
    " \n",
    "\n",
    "    \n",
    "def vectorize_tokens(token_list, word_emb, dim=50):\n",
    "    \"\"\"\n",
    "    Function that vectorize phrases from a counter\n",
    "    \"\"\"\n",
    "    ctr = 0.0\n",
    "    vec = np.zeros(dim)\n",
    "    for token in token_list:\n",
    "        if token in word_emb:\n",
    "            vec += word_emb[token].astype(float)\n",
    "            ctr += 1\n",
    "    if ctr == 0 :\n",
    "        return vec\n",
    "    else:\n",
    "        return vec / float(ctr)\n",
    "    \n",
    "def emb_dist(row, embedding):\n",
    "    \"\"\"\n",
    "    Function that calculates the euclidean distance among two embeddings\n",
    "    \"\"\"\n",
    "    # embedding\n",
    "    emb1 = vectorize_tokens(row[\"token_1\"], embedding)\n",
    "    emb2 = vectorize_tokens(row[\"token_2\"], embedding)\n",
    "    return np.linalg.norm(emb1-emb2)\n",
    "\n",
    "def emb_diff(row, embedding, emb_mat):\n",
    "    \"\"\"\n",
    "    Function that calculates the euclidean distance among two embeddings\n",
    "    \"\"\"\n",
    "    # embedding\n",
    "    emb1 = vectorize_tokens(row[\"token_1\"], embedding)\n",
    "    emb2 = vectorize_tokens(row[\"token_2\"], embedding)\n",
    "    emb_mat.append(np.abs(emb1-emb2))\n",
    "     \n",
    "\n",
    "def feature_engineering(df, embedding=glove_emb, normalize=False, stops=stops):\n",
    "    \"\"\"\n",
    "    Feature engineering function\n",
    "    \"\"\"\n",
    "    total_begin = time.time()\n",
    "    \n",
    "    # preprocessing #\n",
    "    # tokenization\n",
    "    df['token_1'] = df.apply(lambda x: nltk.word_tokenize(x[\"clean_q1\"]), 1)\n",
    "    df['token_2'] = df.apply(lambda x: nltk.word_tokenize(x[\"clean_q2\"]), 1)\n",
    "    # spacy rep\n",
    "    df['doc1'] = df.apply(lambda x: nlp(unicode(x[\"clean_q1\"], \"utf-8\")), 1)\n",
    "    df['doc2'] = df.apply(lambda x: nlp(unicode(x[\"clean_q2\"], \"utf-8\")), 1)\n",
    "    # capitalized spacy rep\n",
    "    df['cap_doc1'] = df.apply(lambda x: nlp(unicode(x[\"clean_q1\"].upper(), \"utf-8\")), 1)\n",
    "    df['cap_doc2'] = df.apply(lambda x: nlp(unicode(x[\"clean_q2\"].upper(), \"utf-8\")), 1)\n",
    "    # entity\n",
    "    df['entity_set_1'] = df.apply(lambda x: x[\"cap_doc1\"].ents, 1)\n",
    "    df['entity_set_2'] = df.apply(lambda x: x[\"cap_doc2\"].ents, 1)\n",
    "    # name chunk\n",
    "    df['noun_chunks_1'] = df.apply(lambda x: [chunk for chunk in x[\"cap_doc1\"].noun_chunks], 1)\n",
    "    df['noun_chunks_2'] = df.apply(lambda x: [chunk for chunk in x[\"cap_doc2\"].noun_chunks], 1)\n",
    "\n",
    "    preprocess_time = time.time()\n",
    "    print(\"preprocessed  for {0} seconds\".format(preprocess_time-total_begin))\n",
    "    \n",
    "    # length #\n",
    "    df.loc[:,\"len_1\"] = df.apply(lambda x: len(x[\"token_1\"]), 1)\n",
    "    df.loc[:,\"len_2\"] = df.apply(lambda x: len(x[\"token_2\"]), 1)\n",
    "    df.loc[:,\"len_diff\"] = np.abs(df[\"len_1\"]-df[\"len_2\"])\n",
    "    df.loc[:,\"len_diff_percent\"] = np.abs(df[\"len_1\"]-df[\"len_2\"]) /((df[\"len_1\"]+df[\"len_2\"])/2)\n",
    "    after_length = time.time()\n",
    "    print(\"length fueature loaded for {0} seconds\".format(after_length-preprocess_time))\n",
    "    \n",
    "    # first words match #\n",
    "    df.loc[:,\"first_word_q1\"] = df.apply(lambda x: x[\"clean_q1\"].split(\" \")[0], 1)\n",
    "    df.loc[:,\"first_word_q2\"] = df.apply(lambda x: x[\"clean_q2\"].split(\" \")[0], 1)\n",
    "    df.loc[:,\"first_word_match\"] = (df[\"first_word_q1\"] == df[\"first_word_q2\"])\n",
    "    after_first = time.time()\n",
    "    print(\"first word feature loaded for {0} seconds\".format(after_first-after_length))\n",
    "    \n",
    "    # bag of words #\n",
    "#     if tokenizer is None:\n",
    "#         bag_of_word_tokenizer = CountVectorizer(stop_words=\"english\", max_features=top_k_word)\n",
    "#     else:\n",
    "#         bag_of_word_tokenizer = tokenizer\n",
    "#     q1_matrix = bag_of_word_tokenizer.fit_transform(df[\"clean_q1\"]).astype(np.float)\n",
    "#     q2_matrix = bag_of_word_tokenizer.fit_transform(df[\"clean_q2\"]).astype(np.float)\n",
    "#     df[\"vec_q1\"] = [q1_matrix[i] for i in range(len(df))]\n",
    "#     df[\"vec_q2\"] = [q2_matrix[i] for i in range(len(df))]\n",
    "#     print(\"question vectorized\")\n",
    "\n",
    "    \n",
    "    # similarity measure #\n",
    "    #cosine_sim = [cosine_similarity(q1_matrix[i], q2_matrix[i])[0][0] for i in range(len(df))]\n",
    "    #df[\"cosine_sim\"] = cosine_sim\n",
    "    #Overlap percent\n",
    "    df.loc[:,\"overlap_percent\"] = df.apply(word_overlap, 1)\n",
    "    df.loc[:,\"overlap_no_stops\"] = df.apply(overlap_no_stops, 1)    \n",
    "    # Spacy stentence similarity\n",
    "    df.loc[:,\"spacy_sentence_similarity\"] = df.apply(sentence_similarity, 1)\n",
    "    # edit distance\n",
    "    df.loc[:,\"edit_distance\"] = df.apply(lambda x: nltk.edit_distance(x[\"token_1\"], x[\"token_2\"]), 1)\n",
    "    # token Jaccard\n",
    "    df.loc[:,\"token_jaccard\"] = df.apply(lambda x: jaccard_sim(set(x[\"token_1\"]), set(x[\"token_2\"])), 1)\n",
    "    after_sim = time.time()\n",
    "    print(\"similarity feature loaded for {0} seconds\".format(after_sim-after_first))\n",
    "    \n",
    "    # embedding #\n",
    "    # embedding diff -- UGLY\n",
    "    dim_emb = embedding.values()[0].shape[0]\n",
    "    emb_mat = []\n",
    "    df.apply(lambda x: emb_diff(x, embedding, emb_mat), 1)\n",
    "    emb_mat = np.array(emb_mat)\n",
    "    for dim in range(dim_emb):\n",
    "        df[\"emb_diff_dim_{0}\".format(dim)] = emb_mat[:,dim]\n",
    "    # euclidean distance - embedding\n",
    "    df.loc[:,\"emb_dist\"] = df.apply(lambda x: emb_dist(x, embedding), 1)\n",
    "    after_emb = time.time()\n",
    "    print(\"embedding feature loaded for {0} seconds\".format(after_emb-after_sim))\n",
    "    \n",
    "    # entity features #\n",
    "    # entity same\n",
    "    df.loc[:,\"entity_same\"] = df.apply(lambda x: x[\"entity_set_1\"]==x[\"entity_set_2\"], 1)\n",
    "    # entity # same\n",
    "    df.loc[:,\"entity_len_same\"] = df.apply(lambda x: len(x[\"entity_set_1\"])==len(x[\"entity_set_2\"]), 1)\n",
    "    # entity # diff\n",
    "    df.loc[:,\"entity_len_diff\"] = df.apply(lambda x: np.abs(len(x[\"entity_set_1\"])-len(x[\"entity_set_2\"])), 1)\n",
    "    # entity Jaccard\n",
    "    df.loc[:,\"entity_jaccard\"] = df.apply(lambda x: jaccard_sim_unhashbale(x[\"entity_set_1\"], x[\"entity_set_2\"]), 1)\n",
    "    \n",
    "    # noun chunk same\n",
    "    df.loc[:, \"chunk_same\"] = df.apply(lambda x: x[\"noun_chunks_1\"]==x[\"noun_chunks_2\"], 1)\n",
    "    # noun chunk # same\n",
    "    df.loc[:,\"chunk_len_same\"] = df.apply(lambda x: len(x[\"noun_chunks_1\"])==len(x[\"noun_chunks_2\"]), 1)\n",
    "    # noun chunk # diff\n",
    "    df.loc[:,\"chunk_len_diff\"] = df.apply(lambda x: np.abs(len(x[\"noun_chunks_1\"])-len(x[\"noun_chunks_2\"])), 1)\n",
    "    # noun chunk Jaccard\n",
    "    df.loc[:,\"chunk_jaccard\"] = df.apply(lambda x: jaccard_sim_unhashbale(x[\"noun_chunks_1\"], x[\"noun_chunks_2\"]), 1)\n",
    "    after_entity = time.time()\n",
    "    print(\"entity feature loaded for {0} seconds\".format(after_entity-after_emb))\n",
    "    \n",
    "    \n",
    "    # filter columns\n",
    "    ignore_columns = [\"first_word_q1\", \"first_word_q2\", \"clean_q1\", \"clean_q2\", \"token_1\", \"token_2\", \n",
    "                      \"doc1\", \"doc2\", \"cap_doc1\", \"cap_doc2\", \"noun_chunks_1\", \"noun_chunks_2\",\n",
    "                     \"entity_set_1\", \"entity_set_2\"]\n",
    "    col_normalize = ['len_1', 'len_2', 'len_diff', 'edit_distance', 'emb_dist', 'entity_len_diff', 'chunk_len_diff']\n",
    "    #full_feature_df = df\n",
    "    clean_feature_df = df.drop(ignore_columns, axis=1)\n",
    "    if normalize:\n",
    "        for col in clean_feature_df.columns:\n",
    "            if str(col) in col_normalize:\n",
    "                col_max = np.max(clean_feature_df[col])\n",
    "                col_min = np.min(clean_feature_df[col])\n",
    "                clean_feature_df[col] = (clean_feature_df[col]-col_min)/float(col_max-col_min)\n",
    "    after_normalize = time.time()\n",
    "    print(\"normalization time = {0}\".format(time.time()-after_normalize))\n",
    "    print(\"total time = {0}\".format(time.time()-total_begin))\n",
    "    return clean_feature_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DATA CREATION SCRIPTS\n",
    "# Quora Dataset\n",
    "#full_data = pd.read_csv(\"../data/questions.csv\")\n",
    "# Kaggle Dataset\n",
    "# begin_time = time.time()\n",
    "# kaggle_train = pd.read_csv(\"../data/kaggle_competition/origin/train.csv\")\n",
    "# kaggle_test = pd.read_csv(\"../data/kaggle_competition/origin/test.csv\")\n",
    "# print(\"data loaded, used {0} seconds\".format(time.time()-begin_time))\n",
    "\n",
    "# clean dataset\n",
    "# begin_time = time.time()\n",
    "# clean_train = clean_dataset(kaggle_train)\n",
    "# clean_test = clean_dataset(kaggle_test)\n",
    "#clean_train.to_csv(\"../data/kaggle_competition/clean_datasets/clean_train.csv\", index=False)\n",
    "#clean_test.to_csv(\"../data/kaggle_competition/clean_datasets/clean_test.csv\", index=False)\n",
    "#print(\"data cleaned, used {0} seconds\".format(time.time()-begin_time))\n",
    "\n",
    "\n",
    "# split and save dataset\n",
    "#begin_time = time.time()\n",
    "# since Kaggle has its own test set, test_ratio=0\n",
    "# train_set, validation_set, _ = split_dataset(clean_train, 0.8, 0.2, 0)\n",
    "# test_set = clean_test\n",
    "# train_set.to_csv(\"../data/kaggle_competition/clean_kaggle_train.csv\", index=False)\n",
    "# validation_set.to_csv(\"../data/kaggle_competition/clean_kaggle_validation.csv\", index=False)\n",
    "# test_set.to_csv(\"../data/kaggle_competition/clean_kaggle_test.csv\", index=False)\n",
    "# load splitted dataset\n",
    "train_set, validation_set, test_set = load_datasets()\n",
    "# print(\"data splitted, used {0} seconds\".format(time.time()-begin_time))\n",
    "\n",
    "\n",
    "# feature engineering\n",
    "# begin_time = time.time()\n",
    "# feature_train = feature_engineering(train_set)\n",
    "# feature_train.to_csv(\"../data/kaggle_competition/feature_datasets/feature_train_v2.csv\", index=False)\n",
    "# feature_validation = feature_engineering(validation_set)\n",
    "# feature_validation.to_csv(\"../data/kaggle_competition/feature_datasets/feature_validation_v2.csv\", index=False)\n",
    "# feature_test = feature_engineering(test_set)\n",
    "# feature_test.to_csv(\"../data/kaggle_competition/feature_datasets/feature_test_v2.csv\", index=False)\n",
    "# print(\"data featurized, used {0} seconds\".format(time.time()-begin_time))\n",
    "feature_train, feature_validation, feature_test= load_datasets(load_dir = \"../data/kaggle_competition/\", prefix=\"feature_\", post_fix=\"_v2\")\n",
    "# load splitted dataset\n",
    "# train_set, validation_set, test_set = load_datasets()\n",
    "# print(\"data splitted, used {0} seconds\".format(time.time()-begin_time))\n",
    "\n",
    "# split X, y\n",
    "#X_train, y_train = xy_split(feature_train)\n",
    "#X_validate, y_validate = xy_split(feature_validation)\n",
    "#X_test=feature_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(train_set))\n",
    "print(len(validation_set))\n",
    "print(len(test_set))\n",
    "feature_train = feature_engineering(train_set.head(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print (X_validate.shape)\n",
    "print (y_validate.shape)\n",
    "print (X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mat1 = full_feature_df[\"vec_q1\"].iloc[0]\n",
    "#mat2 = full_feature_df[\"vec_q2\"].iloc[0]\n",
    "\n",
    "#cosine_similarity(mat1[5], mat2[5])\n",
    "#a = time.time()\n",
    "#cosine_similarity(full_feature_df[\"vec_q1\"].iloc[10],full_feature_df[\"vec_q2\"].iloc[10] )\n",
    "#print time.time()-a\n",
    "#len(full_feature_df)\n",
    "#full_feature_df.to_csv(\"../data/full_feature_df.csv\", index=False)\n",
    "#np.sum(clean_feature_df[\"cosine_sim\"]==0)/float(len(clean_feature_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mat1 = mat1.astype(np.float)\n",
    "#mat2 = mat2.astype(np.float)\n",
    "#cosine_similarity(mat1, mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PREDICTIVE MODEL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MODEL ANALYTICS FUNCTIONS\n",
    "def all_test_metrics(y_pred, y_test, metrics_list=[\"acc\", \"auc\", \"f1\", \"nll\"]):\n",
    "    score_dict = {}\n",
    "    # acc\n",
    "    if \"acc\" in metrics_list:\n",
    "        y_pred_acc = np.round(y_pred).astype(np.int8)\n",
    "        acc = metrics.accuracy_score(y_test, y_pred_acc, normalize=True)\n",
    "        score_dict[\"acc\"] = acc \n",
    "    # auc\n",
    "    if \"auc\" in metrics_list:\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        score_dict[\"auc\"] = auc\n",
    "        #score_dict[\"fpr\"] = fpr\n",
    "        #score_dict[\"tpr\"] = tpr\n",
    "    # f1-measure\n",
    "    if \"f1\" in metrics_list:\n",
    "        y_pred_acc = np.round(y_pred).astype(np.int8)\n",
    "        f1 = metrics.f1_score(y_test, y_pred_acc, labels=[0,1], pos_label=1)\n",
    "        score_dict[\"f1\"] = f1\n",
    "    # nll\n",
    "    if \"nll\" in metrics_list:\n",
    "        nll = metrics.log_loss(y_test, y_pred)\n",
    "        score_dict[\"nll\"] = nll\n",
    "    return score_dict\n",
    "\n",
    "\n",
    "def test_model(model, X_test, y_test, verbose=True, model_name=\"\", y_pred_test=None, pred_lambda=None):\n",
    "    \"\"\"\n",
    "    Function that generate performance stats for a model\n",
    "    \"\"\"\n",
    "    if y_pred_test is None:\n",
    "        if pred_lambda is None:\n",
    "            y_pred_test = model.predict(X_test)\n",
    "        else:\n",
    "            y_pred_test = pred_lambda(model, X_test)  \n",
    "    scores = all_test_metrics(y_pred_test, y_test)    \n",
    "    if verbose:\n",
    "        print(model_name+\":\")\n",
    "        print(scores)\n",
    "    return y_pred_test, scores\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MODEL ANALYTICS SCRIPT\n",
    "n_valid = len(validation_set)\n",
    "n_test = len(test_set)\n",
    "\n",
    "# baseline 1: majority class\n",
    "y_pred_valid = [0 for i in range(n_valid)]\n",
    "#y_pred_test = [0 for i in range(n_test)]\n",
    "_, score_majority_class_valid = test_model(None, None, y_validate, \n",
    "                                        verbose=True, model_name=\"Baseline 1 - Majority Class (Validation):\",\n",
    "                                        y_pred_test=y_pred_valid)\n",
    "\n",
    "# baseline 2: simple word overlap\n",
    "y_pred_valid = X_validate[:,5].astype(np.double)\n",
    "#y_pred_test = X_test[:,5].astype(np.double)\n",
    "_, score_majority_class_valid = test_model(None, None, y_validate, \n",
    "                                        verbose=True, model_name=\"Baseline 2 - Simple Word Overlap (Validation):\",\n",
    "                                        y_pred_test=y_pred_valid)\n",
    "\n",
    "# baseline 3: logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr_lambda = lambda model, x: model.predict_proba(x)[:,1]\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred_valid, score_majority_class_valid = test_model(lr, X_validate, y_validate, verbose=True,\n",
    "                                                       model_name=\"Baseline 3 - Simple Logistic Regression (Validation):\",\n",
    "                                                      pred_lambda=lr_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = xy_split(feature_train)\n",
    "X_validate, y_validate = xy_split(feature_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.643507\tvalid-logloss:0.643459\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.516641\tvalid-logloss:0.518384\n",
      "[20]\ttrain-logloss:0.500871\tvalid-logloss:0.504695\n",
      "[30]\ttrain-logloss:0.494178\tvalid-logloss:0.499938\n",
      "[40]\ttrain-logloss:0.487985\tvalid-logloss:0.496377\n",
      "[50]\ttrain-logloss:0.482687\tvalid-logloss:0.493426\n",
      "[60]\ttrain-logloss:0.478363\tvalid-logloss:0.491634\n",
      "[70]\ttrain-logloss:0.474179\tvalid-logloss:0.490038\n",
      "[80]\ttrain-logloss:0.471028\tvalid-logloss:0.488876\n",
      "[90]\ttrain-logloss:0.467795\tvalid-logloss:0.48784\n",
      "[100]\ttrain-logloss:0.464972\tvalid-logloss:0.487171\n",
      "[110]\ttrain-logloss:0.461326\tvalid-logloss:0.486216\n",
      "[120]\ttrain-logloss:0.458852\tvalid-logloss:0.48565\n",
      "[130]\ttrain-logloss:0.456077\tvalid-logloss:0.484956\n",
      "[140]\ttrain-logloss:0.453539\tvalid-logloss:0.484286\n",
      "[150]\ttrain-logloss:0.451763\tvalid-logloss:0.483978\n",
      "[160]\ttrain-logloss:0.450253\tvalid-logloss:0.483742\n",
      "[170]\ttrain-logloss:0.448212\tvalid-logloss:0.482981\n",
      "[180]\ttrain-logloss:0.446838\tvalid-logloss:0.482703\n",
      "[190]\ttrain-logloss:0.445082\tvalid-logloss:0.482464\n",
      "[200]\ttrain-logloss:0.443842\tvalid-logloss:0.482329\n",
      "[210]\ttrain-logloss:0.442487\tvalid-logloss:0.482236\n",
      "[220]\ttrain-logloss:0.440977\tvalid-logloss:0.48204\n",
      "[230]\ttrain-logloss:0.439925\tvalid-logloss:0.481948\n",
      "[240]\ttrain-logloss:0.438668\tvalid-logloss:0.48188\n",
      "[250]\ttrain-logloss:0.437132\tvalid-logloss:0.48172\n",
      "[260]\ttrain-logloss:0.43566\tvalid-logloss:0.481523\n",
      "[270]\ttrain-logloss:0.434351\tvalid-logloss:0.481604\n",
      "[280]\ttrain-logloss:0.43322\tvalid-logloss:0.481587\n",
      "[290]\ttrain-logloss:0.431923\tvalid-logloss:0.48143\n",
      "[300]\ttrain-logloss:0.430574\tvalid-logloss:0.48121\n",
      "[310]\ttrain-logloss:0.42934\tvalid-logloss:0.481125\n",
      "[320]\ttrain-logloss:0.428213\tvalid-logloss:0.481107\n",
      "[330]\ttrain-logloss:0.42678\tvalid-logloss:0.481005\n",
      "[340]\ttrain-logloss:0.425628\tvalid-logloss:0.480991\n",
      "[350]\ttrain-logloss:0.424743\tvalid-logloss:0.481012\n",
      "[360]\ttrain-logloss:0.423519\tvalid-logloss:0.481081\n",
      "[370]\ttrain-logloss:0.422076\tvalid-logloss:0.480895\n",
      "[380]\ttrain-logloss:0.421196\tvalid-logloss:0.480864\n",
      "[390]\ttrain-logloss:0.42021\tvalid-logloss:0.48095\n",
      "[400]\ttrain-logloss:0.418962\tvalid-logloss:0.480929\n",
      "[410]\ttrain-logloss:0.417871\tvalid-logloss:0.48091\n",
      "[420]\ttrain-logloss:0.416829\tvalid-logloss:0.480931\n",
      "Stopping. Best iteration:\n",
      "[375]\ttrain-logloss:0.421497\tvalid-logloss:0.480825\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11303e6a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAEWCAYAAAD/3UTfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xl4VdX1//H3h0FEQFARfihqRFRiIERAcEAbqoAMzlUc\naEWhlDqARUVbilInsIqK09cKFSxYAadiHQFpUBGnAIJgQVujDFYEFYkEDLB+f5yd5BIScgO5SeCu\n1/Pk8d599tlnnU3MWXeffc+WmeGcc8655FOjqgNwzjnnXNXwJMA555xLUp4EOOecc0nKkwDnnHMu\nSXkS4JxzziUpTwKcc865JOVJgHMu6Uh6TNKIqo7Duaomf06Acy5eknKApsDWmOJjzGz1brSZCUw2\ns+a7F92eSdJEYKWZ/bGqY3HJx0cCnHPldZaZ1Y/52eUEoCJIqlWVx98dkmpWdQwuuXkS4JyrEJJO\nlPSOpO8lfRQ+4Rdsu0LSJ5I2SPqvpN+E8nrAq8AhknLDzyGSJkq6I2b/TEkrY97nSLpJ0iLgR0m1\nwn7PSfpG0ueSBu8k1sL2C9qWNEzSGklfSTpXUk9JyyV9K+kPMfuOlPSspKnhfOZLahuzPVVSVuiH\nJZLOLnbc/5P0iqQfgf7AZcCwcO7/DPVulvSf0P5SSefFtNFP0tuS7pX0XTjXHjHbD5Q0QdLqsP0f\nMdt6S1oYYntHUnrc/8Bur+RJgHNut0k6FHgZuAM4ELgBeE7SwaHKGqA3sD9wBXC/pHZm9iPQA1i9\nCyMLlwC9gEbANuCfwEfAocDpwHWSusfZ1v8D9g373gKMA/oC7YFTgVsktYipfw7wTDjXvwP/kFRb\nUu0QxwygCXAt8JSkY2P2vRS4E2gA/A14CvhzOPezQp3/hOM2BP4ETJbULKaNTsAyoDHwZ+CvkhS2\nTQL2A9JCDPcDSGoHPAH8BjgI+AvwoqQ6cfaR2wt5EuCcK69/hE+S38d8yuwLvGJmr5jZNjObCXwI\n9AQws5fN7D8WmUN0kTx1N+N40MxWmFkecAJwsJndZmY/mdl/iS7kF8fZVj5wp5nlA1OILq5jzWyD\nmS0BlgCxn5qzzezZUP8+ogTixPBTHxgd4pgNvESUsBSYbmZzQz9tKikYM3vGzFaHOlOBT4GOMVW+\nMLNxZrYVeBJoBjQNiUIPYJCZfWdm+aG/AX4N/MXM3jOzrWb2JLA5xOyS1B57L805V2XONbNZxcqO\nAC6UdFZMWW3gXwBhuPpW4BiiDx/7AYt3M44VxY5/iKTvY8pqAm/F2da6cEEFyAv//Tpmex7RxX2H\nY5vZtnCr4pCCbWa2LabuF0QjDCXFXSJJvwKGAimhqD5RYlLgfzHH3xgGAeoTjUx8a2bfldDsEcDl\nkq6NKdsnJm6XhDwJcM5VhBXAJDP7dfENYbj5OeBXRJ+C88MIQsHwdUlfUfqRKFEo8P9KqBO73wrg\nczM7eleC3wWHFbyQVANoDhTcxjhMUo2YROBwYHnMvsXPd7v3ko4gGsU4HZhnZlslLaSov3ZmBXCg\npEZm9n0J2+40szvjaMclCb8d4JyrCJOBsyR1l1RT0r5hwl1zok+bdYBvgC1hVKBbzL5fAwdJahhT\nthDoGSa5/T/gujKO/z7wQ5gsWDfE0FrSCRV2httrL+n88M2E64iG1d8F3iNKYIaFOQKZwFlEtxhK\n8zUQO9+gHlFi8A1EkyqB1vEEZWZfEU20fFTSASGG08LmccAgSZ0UqSepl6QGcZ6z2wt5EuCc221m\ntoJostwfiC5eK4AbgRpmtgEYDEwDviOaGPdizL7/Bp4G/hvmGRxCNLntIyCHaP7A1DKOv5XoYpsB\nfA6sBcYTTaxLhOlAH6Lz+SVwfrj//hNwNtF9+bXAo8CvwjmW5q/AcQVzLMxsKTAGmEeUILQB5pYj\ntl8SzXH4N9GEzOsAzOxDonkBD4e4PwP6laNdtxfyhwU551w5SBoJtDSzvlUdi3O7y0cCnHPOuSTl\nSYBzzjmXpPx2gHPOOZekfCTAOeecS1L+nABXZRo1amQtW7as6jCqhR9//JF69epVdRjVgvdFEe+L\nIt4XRbKzs9ea2cFl1yybJwGuyjRt2pQPP/ywqsOoFrKyssjMzKzqMKoF74si3hdFvC+KSPqiotry\n2wHOOedckvIkwDnnnEtSngQ455xzScqTAOeccy5JeRLgnHPOJSlPApxzzrkk5UmAc845l6Q8CXDO\nOeeSlCcBzjnnXJLyJMA555xLUp4EOOecc0nKkwDnnHMuSXkS4JxzziUpTwKcc865JOVJgHPOObeL\nVqxYQZcuXUhNTSUtLY2xY8cCcOONN9KqVSvS09M577zz+P777wF46qmnyMjIKPypUaMGCxcuBOCn\nn35i4MCBHHPMMbRq1Yrnnnsu4fF7EuCcc87tolq1ajFmzBg++eQT3n33XR555BGWLl1K165d+fjj\nj1m0aBHHHHMMo0aNAuCyyy5j4cKFLFy4kEmTJpGSkkJGRgYAd955J02aNGH58uUsXbqUn/3sZ4mP\nP+FH2AtIygAOMbNXqjqW4iS9Y2Ynl6P+IGCjmf1N0kTgJTN7dhf37wfMMLPV5Y0bIC9/Kyk3v7wr\nu+51rm+zhX7eF4D3RSzviyLVsS9yRveiWbNmNGvWDIAGDRqQmprKqlWr6NatW2G9E088kWef3fHP\n7NNPP80ll1xS+P6JJ57g3//+NwA1atSgcePGCT4DHwmIVwbQs6qDKEl5EoBQ/zEz+9uuHEtSrWL7\n9wMO2ZW2nHNub5OTk8OCBQvo1KnTduVPPPEEPXr02KH+1KlTC5OAgtsFI0aMoF27dlx44YV8/fXX\nCY85YSMBkuoB04DmQE3gduBuYCrQJVS71Mw+k3QW8EdgH2AdcJmZfS2pPvAQ0AEw4E9AI6C1mf0u\nHOfXQKqZDY0nBjObKqk9cB9QH1gL9DOzryRlAe+F+BoB/cP724C6kjoDo4CXQlxtiPpwpJlND5+M\nzwb2A44CXjCzYSGWM4G7Qhxrzez0EN8O7ZTSn2nAhNBHNYALzOxTSblmVl9SZuifr4mSlueBxcAQ\noC5wrpn9R9JIINfM7i3W/i3AWaHuO8BvzMxCn7wDnAK8KKkBkAvkhH+XpyTlAcOBAWZ2XmivK/Bb\nMzu/2HEGAgMBGjc+mFvabCnpdJNO07rRJx3nfRHL+6JIdeyLrKyswtd5eXkMGTKEAQMGMH/+/MLy\nyZMn8/3333PooYduV3/p0qWYGWvXriUrK4v169ezcuVKGjZsyH333ce0adP45S9/yR/+8IeEnkMi\nbwecCaw2s14AkhoSJQE/mFlHSb8CHgB6A28DJ4aLzgBgGHA9MAJYb2ZtQhsHAD8BiyQNM7N84Arg\nN/HGIKk20YX3HDP7RlIf4E7gyrBPrRBfT+BWMzsjXCA7mNk1oZ27gNlmdqWkRsD7kmaF/TOA44HN\nwDJJDwGbgHHAaWb2uaQDQ93hJbVjZj+WcC6DgLFm9pSkfYiSieLaAqnAt8B/gfHhXIYA1wLXldJP\nAA+b2W3h/CYR/bv8M2xrZGY/C9tGApjZs5KuAW4wsw8lCRgj6WAz+4bo32VC8YOY2ePA4wCHt2hp\nYxb7HSmI/rh5X0S8L4p4XxSpjn2Rc1kmAPn5+fTu3ZtBgwYxdGjR59Enn3ySJUuW8MYbb7Dffvtt\nt+/06dMZMGAAmZlRG2bGfvvtx4gRI6hRowZHHXUUZ555ZuH2RElkjy4G7pV0N9F957ei6wRPh+1P\nA/eH182BqZKaEX3S/TyUnwFcXNCgmX0HIGk20FvSJ0BtM1tcjhhaA62BmSGemsBXMfs8H/6bDaSU\n0m434GxJN4T3+wKHh9dvmNn6EOdS4AjgAOBNM/s8nMe3ZbTzSQnHnAcMl9QceN7MPi2hzgdm9lU4\n9n+AGTH90KWE+rG6SBpGNIpxILCEoiRgahn7EhK4SUBfSROAk4Bf7WyfurVrsmx0r7KaTgpZWVmF\nf1CSnfdFEe+LItW1L8yM/v37k5qaul0C8Nprr3H33XczZ86cHRKAbdu28cwzz/Dmm28WlknirLPO\nIisri5///Oe88cYbHHfccQmPP2FJgJktD8PuPYFRkgouSBZbLfz3IeA+M3sxDGuPDOUqVr/AeOAP\nwL8p4dNmGTG8ACwxs5NK2W1z+O9WSu8fEQ3HL9uuUOoUs39sG6WdR4ntlHIuf5f0HtALeF3SADOb\nXUrsANti3m/bybkgaV/gUaLRjhXh0/6+MVVKGpkoyQSixGET8IyZVa+xO+ecq2Bz585l0qRJtGnT\npnCW/1133cXgwYPZvHkzXbt2BaLJgY899hgAb775Js2bN6dFixbbtXX33Xfzy1/+kuuuu46DDz6Y\nCRNKvbxVmETOCTgE+NbMJkvKJZpEBtAHGB3+Oy+UNQRWhdeXxzQzA7iGMIwt6QAz+87M3pN0GNAO\nSC9nDKOBgyWdZGbzwu2BY8xsyU5OZwPQIOb968C1kq4Nn4CPN7MFO9l/HvCIpCMLbgeE0YC425HU\nAvivmT0YXqcDxZOAXVVwwV8b5mH8AojnGwPb9YuZrZa0mmh+R9cKis0556qtzp07Y7bjZ7yePUuf\nS56Zmcm77767Q/kRRxyx3ehAZUjktwPaEN3jXkh07/uOUF4nfKIdAvwulI0EnpH0FtFEvQJ3AAdI\n+ljSR2w/pD0NmFtwiyDeGMzsJ6KL3N2hzYVAWTPs/wUcJ2lhmENwO1CbaG7Cx+F9qcI98oHA8+GY\nBcPr5WmnD/BxOJdWwC7N8C8lvu+J5iwsBv4BfBDnrhOBx0K/1A1lTwErzGxpRcXnnHMuMVRSBpOw\ng0k5REPOa8uqG0dbLwH3m9kbux2YqzCSHgYWmNlfy6p77LHH2rJlZd4JSQpZWVkJnwC0p/C+KOJ9\nUcT7ooikbDPrUBFt7XHPCZDUSNJyIM8TgOpFUjbRbYrJVR2Lc865slXq9y3MLKUC2vgeOCa2TNJB\nQEkJwelmtm53j1mZJHUn+iplrM8Lvn9fnZlZ+6qOwTnnXPyq15cud1G40GdUdRwVwcxeJ5ow6Jxz\nziXUHnc7wDnnnHMVw5MA55xzLkl5EuCcc84lKU8CnHPOuSTlSYBzzjmXpDwJcM4555KUJwHOJdjW\nrVs5/vjj6d27NwAPP/wwLVu2RBJr1xY9PPOpp54iPT2d9PR0Tj75ZD766KOqCtk5lyQ8CXAuwcaO\nHUtqamrh+1NOOYVZs2ZxxBFHbFfvyCOPZM6cOSxatIgRI0YwcODAyg7VOZdk9oqHBVUXkhoBl5rZ\nozupkwncYGa9ExTDKyGG7xPRfpwxpAAvmVnrndXLy99Kys0vV0pMlS1ndC8AVq5cycsvv8zw4cO5\n7777ADj++ONL3Ofkk4vWsTrxxBNZuXJl4gN1ziU1HwmoWI2Aq6oyADPrWdkJgKSalXm8Pcl1113H\nn//8Z2rUKN//an/961/p0aNHgqJyzrmIjwRUrNHAUWG535mhrAdgRMsYT42tLOkE4HHgAuBr4CGi\n5Y9rASPNbLqkfsDZwH7AUcALZjastABiV2qU9A/gMGBfYKyZPR7qnAncBdQE1prZ6ZLqh+N3CPH+\nycyek/R/wAlAXeBZM7s15jhPAN2AhyV9Gt5vBN7eSXwDiZZVpnHjg7mlzZbSe3MPlpWVxbx588jP\nz2fDhg0sXLiQdevWkZWVVVhn06ZNzJ07l4YNG5Kbm1u4bcGCBTz00EM8+OCD29VPFrF9key8L4p4\nXySGJwEV62agtZllSLoAGAS0BRoDH0h6s6CipJOJLrrnmNmXku4CZpvZleG2wvuSZoXqGcDxwGZg\nmaSHzGxFHPFcaWbfSqobjv8c0ejPOOA0M/tc0oGh7ghgvZm1CfEdEMqHhzZqAm9ISjezRWHbJjPr\nHOovAq41szmS7iktoJCIPA5weIuWNmbx3vkrmHNZJq+//jrZ2dn069ePTZs28cMPPzB+/HgmT44W\nWdx333055ZRTaNy4ceEyqYsWLeLhhx9m5syZHHPMMWUcZe/kS8YW8b4o4n2RGHvnX+DqoTPwtJlt\nBb6WNIfoE/UPQCrRhbCbma0O9bsBZ0u6IbzfFzg8vH7DzNYDSFoKHAHEkwQMllSw+uBhwNHAwcCb\nZvY5gJl9G7afAVxcsKOZfRdeXhQ+vdcCmgHHAQVJwNQQU0OgkZnNCeWTiEZAdqpu7ZosC/fO90aj\nRo1i1KhRQPQH7N577y1MAEry5Zdfcv755zNp0qSkTQCcc5XL5wQkjnay7StgE9Gn+9j6F5hZRvg5\n3Mw+Cds2x9TbShzJW5iAeAZwkpm1BRYQJRYiGu4vKd7tyiUdCdxAtCRzOvByaKPAj6Xt60r34IMP\n0rx5c1auXEl6ejoDBgwA4LbbbmPdunVcddVVZGRk0KFDhyqO1Dm3t/MkoGJtABqE128CfSTVlHQw\ncBrwftj2PdALuCtcrCFaPvhaSQKQVPIU8vg1BL4zs42SWgEnhvJ5wM/CBZ6Y2wEzgGsKdg63A/Yn\nutCvl9SUUj7dh4mI6yV1DkWX7Wbse53MzExeeuklAAYPHszKlSvZsmULq1evZvz48QCMHz+e7777\njoULF7Jw4UI+/PDDqgzZOZcEPAmoQGa2Dpgr6WPgJKJh84+A2cAwM/tfTN2vgbOARyR1Am4HagOL\nwv63704owGtArXCv/nbg3XDcb4gm5j0v6SPCkD5wB3CApI9DeRcz+4hoBGEJ0aS/uTs55hXhXOYB\nebsRu3POuUricwIqmJldWqzoxmLbs4Cs8PpLIC1m829KaG8iMDHmfanPFwiT9xoAP5hZPqV/cn8V\neLVYWS5weQl1+5XSRkqx99lEkyALjCwtTuecc9WDjwTsXZYA40MC4Jxzzu2UjwTsoSS9B9QpVnyh\nmS2uinicc87teTwJ2EOZWaeqjsE559yezW8HOOecc0nKkwDnnHMuSXkS4JxzziUpTwKcc865JOVJ\ngHPOOZekPAlwzjnnkpQnAc4lwKZNm+jYsSNt27YlLS2NW2+9FYDZs2fTrl07WrduzeWXX86WLVsA\n2LBhA+eddx7p6el07NiRjz/+uCrDd84lCU8CqoikHEmNqzqOiiYpRVLxRycnnTp16jB79mw++ugj\nFi5cyGuvvcY777zD5ZdfzpQpU/j444854ogjePLJJwF46qmnyMjIYNGiRfztb39jyJAhVXwGzrlk\n4A8LqmRhlcCdLTNc6STVMrMtFdRcCnAp8PeyKublbyXl5pcr6LDVR87oXkiifv36AOTn55Ofn0/N\nmjWpU6cOxxxzDABdu3Zl1KhR9O/fn5ycHK65JlrEsVWrVuTk5PD111/TtGnTKjsP59zez0cC4iBp\naFhd72NJ10m6W9JVMdtHSro+vL5R0geSFkn6UyhLkfSJpEeB+cBhxdr/h6RsSUskDYwpz5U0RtJ8\nSW+EJYlLizFL0gOS3glxdgzl9SQ9EWJaIOmcUN5P0jOS/km0jDCShklaLOkjSaND2VGSXgvxvRWW\nJUbSREkPhuP9V9IvQiijgVMlLZT0u93s+j3a1q1bycjIoEmTJnTt2pWOHTuSn59fuETws88+y4oV\nKwA46qijeP755wF4//33+eKLL1i5cmWVxe6cSw4+ElAGSe2JlsntRPQJ/j2gL/AA8GiodhFwpqRu\nwNFAx1D3RUmnAV8CxwJXmNlVod3Yw1xpZt9Kqgt8IOm5sCxxPWC+mV0v6RbgVuCanYRbz8xODsd8\nAmgNDAdmm9mVkhoB70uaFeqfBKSHY/cAzgU6mdlGSQeGOo8Dg8zs07Dk8aPAz8O2ZkBnoBXwIvAs\ncDNwQ2mrHYYkZyBA48YHc0ubihqAqD6ysrIKXz/wwAPk5uYyYsQIWrVqxbBhw7jyyivJz8+nQ4cO\nbNq0iaysLM455xwmTJhAy5YtadGiBS1btmTBggVs2LCh6k6kiuTm5m7Xh8nM+6KI90VieBJQts7A\nC2b2I4Ck54FTgSaSDgEOBr4zsy8lDQa6AQvCvvWJkoIvgS/M7N1SjjFY0nnh9WFhn3XANmBqKJ8M\nPF9GrE8DmNmbkvYPF/1uwNmSbgh19gUOD69nmtm34fUZwAQz2xja+FZSfeBk4JmYpCV20aJ/mNk2\nYKmkuMatzexxosSCw1u0tDGL975fwZzLMncoy87OZt26ddxwww1cffXVAMyYMYPNmzeTmZlJVlYW\nr74are5sZhx55JFcdNFF7L///pUZerWQlZVFZmZmVYdRLXhfFPG+SIy97y9wxSvt/v2zwC+A/wdM\niak7ysz+sl0DUgrwY4mNS5lEF+CTwifwLKILdUmsjFiLb7cQ0wVmtqzYcTsVi0kl7F8D+N7MMko5\n3uZi+5dL3do1WTa6V3l32yN888031K5dm0aNGpGXl8esWbO46aabWLNmDU2aNGHz5s3cfffdDB8+\nHIg+5fz000/ss88+jB8/ntNOOy0pEwDnXOXyOQFlexM4V9J+kuoB5wFvEV34LyZKBJ4NdV8Hrgyf\noJF0qKQmZbTfkGgkYWO4335izLYaoX2IJtu9XUZbfcJxOwPrzWx9iOnaMCERSceXsu+MEPt+od6B\nZvYD8LmkC0OZJLUtI4YNQIMy6uz1vvrqK7p06UJ6ejonnHACXbt2pXfv3txzzz2kpqaSnp7OWWed\nxc9/Ht1Z+eKLL0hLS6NVq1a8+uqrjB07torPwDmXDHwkoAxmNl/SROD9UDTezBYASGoArDKzr0Ld\nGZJSgXnhmptLNH9g604O8RowSNIiYBkQe8vgRyBNUjawnnCR34nvJL0D7A9cGcpuJ5q/sCgkAjnA\nDvfrzew1SRnAh5J+Al4B/gBcBvyfpD8CtYmSn492EsMiYIukj4CJZnZ/GTHvldLT01mwYMEO5ffc\ncw/33HPPDuVpaWl8+umnlRGac84V8iQgDmZ2H3BfCeVtSigbC5T0Ma51sXopMW977OTYI4ARcYb6\nnJn9vtj+ecBvSmh3IjCxWNlootn9sWWfA2eWsH+/Yu/rh//mA6fHGa9zzrkq5LcDnHPOuSTlIwHV\nWMGn61iSHgFOKVY81swyKyUo55xzew1PAvYwZnZ1VcfgnHNu7+C3A5xzzrkk5UmAc845l6Q8CXDO\nOeeSlCcBzjnnXJLyJMA555xLUp4EOOecc0nKkwDnKtCmTZvo2LEjbdu2JS0tjVtvvRWAN954g3bt\n2pGRkUHnzp357LPPCveZNm0a/fr1Iy0tjUsvvbSqQnfOJSF/ToBzFahOnTrMnj2b+vXrk5+fT+fO\nnenRowe//e1vmT59OqmpqTz66KPccccdTJw4kU8//ZRRo0bx0EMPcdZZZ7FmzZqqPgXnXBLxJKAK\nSeoHdDCzayQNAjaa2d9C+QwzWx1nO5nADWbWW9LZwHFhHYCS6mYAh5jZKxVyErshL38rKTe/XNVh\nVJic0b2QRP360YMe8/Pzyc/PRxKS+OGHHwBYv349hxxyCADjxo3j6quvpkGDaOHFJk3KWnTSOecq\njicB1YSZPRbzth/wMRBXElCsnReBF3dSJQPoQLRKoEuArVu30r59ez777DOuvvpqOnXqxPjx4+nZ\nsyd169Zl//335913o8Uily9fDsADDzxA/fr1GTlyJGeeucN6Tc45lxAys6qOYa8lqS8wGNgHeA+4\nCvgV8HvgK2A5sDmMBIwkWno4h2h1v1VAHnBSWAmweNtnEi0RvBaYD7QIIwH9KBpduBC4lWgp4/XA\nGcBnQN3Q/ijg89BO3XC8K8xsWWjnbGA/4CjgBTMbFnPsu4CawFozO11SPeAhoA1RcjnSzKaXEPdA\nYCBA48YHt7/lgXHl7dZqq82hDbd7n5uby4gRIxg8eDATJkzg4osv5rjjjmPKlCmsWLGCG2+8kd//\n/vfUqlWL66+/nry8vMK6BaMJySg3Nzepzz+W90UR74siXbp0yTazDhXRlo8EJIikVKAPcIqZ5Ut6\nFOgL/AloT3RR/hew3aLzZvaspGuIhvc/LKXtfYFxwM+JLupTSwnjFqC7ma2S1MjMfpJ0CyFJCG3t\nD5xmZlsknUF0cb8g7J8BHA9sBpZJegjYFI59mpl9LunAUHc4MNvMrpTUCHhf0iwz+7HY+T0OPA5w\neIuWNmbx3vMrmHNZ5g5l2dnZrF27llWrVnHVVVcB0KJFC84880wyMzNp27YtJ554Io0aNeLcc89l\n/PjxNG3alBNOOKGSo68+srKyyMzMrOowqgXviyLeF4mx9/wFrn5OJ7rYfyAJok/aJwNZZvYNgKSp\nwDG70HYr4HMz+zS0M5nw6bqYucBESdOA50tpqyHwpKSjAQNqx2x7w8zWh2MsBY4ADgDeNLPPAczs\n21C3G3C2pBvC+32Bw4FPSjuJurVrsmx0r7LOdY/yzTffULt2bRo1akReXh6zZs3ipptuYv369Sxf\nvpxjjjmGmTNnkpqaCsC5557L008/zRVXXMHatWtZvnw5LVq0qOKzcM4lC08CEkfAk2b2+8IC6Vzg\nvApqv8z7OGY2SFInoBewMEwKLO524F9mdp6kFCArZtvmmNdbiX5fVMqxBVxgZsviin4v9dVXX3H5\n5ZezdetWtm3bxkUXXUTv3r0ZN24cF1xwATVq1OCAAw7giSeeAKB79+7MmDGDfv360aBBA+655x4O\nOuigKj4L51yy8CQgcd4Apku638zWhGHzBcBYSQcBPwAXAh+VsO8GoMFO2v43cKSko8zsP8AlJVUK\n298D3pN0FnBYCW03JJofANGExLLMAx6RdGTB7YAwGvA6cK2ka83MJB1vZgvKaGuvk56ezoIFO572\neeedx3nn7Zj/SeK+++7j7LPP9qFO51yl84cFJYiZLQX+CMyQtAiYCTQDRhJdSGcRTegryUTgMUkL\nJdUtoe1NRMP/L0t6G/iilHbukbRY0sfAm0QJx7+A40LbfYA/A6MkzSWa6FfWeX0Tjv28pI8omo9w\nO9GthEXheLeX1ZZzzrmq5SMBCWRmU9lx0t67wIQS6o6Mef0c8FwZbb9GNDegePlEoiQCMzu/hF2/\nBYrPOoudlzCieDvhfe+Y168CrxY7bh7wm53F7JxzrnrxkQDnnHMuSflIQDUn6QXgyGLFN5nZ61UR\nj3POub3bYv54AAAgAElEQVSHJwHVnJlV1LcJnHPOue347QDnnHMuSZU7CZB0gKT0RATjnHPOucoT\nVxIgKUvS/uG77h8BEyTdl9jQnHPOOZdI8Y4ENDSzH4DzgQlm1p5oMRrnnHPO7aHiTQJqSWoGXAS8\nlMB4nHPOOVdJ4k0CbiN6LOx/zOwDSS2ATxMXlnPOOecSLa4kwMyeMbN0M/tteP9fM7ugrP2c21ts\n2rSJjh070rZtW9LS0rj11lsBePjhh2nZsiWSWLt2bWH9rKwsGjZsSEZGBhkZGdx2221VFbpzzpUq\nrucESDoG+D+gqZm1Dt8OONvM7khodM5VE3Xq1GH27NnUr1+f/Px8OnfuTI8ePTjllFPo3bt3iYv/\nnHrqqbz0kt89c85VX/E+LGgccCPwFwAzWyTp74AnATEk9QM6mNk1u7DvSCDXzO6VdBvwppnNknQq\n8BiQD5xEdGumJ/CKmd0YR7u5ZlZf0iHAg2b2i/LGVqy924FzgG3AGqCfma2WJGBsiG1jKC9tgSQA\n8vK3knLzy7sTTqXIGd0LSdSvXx+A/Px88vPzkcTxxx9fxdE559yui3dOwH5m9n6xsi0VHYyLmNkt\nZjYrvL0MuNfMMmIW6WkXTwJQrM3Vu5sABPeEW0MZRJNEbwnlPYCjw89AopGjvcrWrVvJyMigSZMm\ndO3alU6dOu20/rx582jbti09evRgyZIllRSlc87FL96RgLWSjgIMQNIvgK8SFlUVk9QXGAzsA7wH\nXAWsBx4h+mrkd8AfiJbhPRy4zsxeDLsfJuk1ouf9/93M/rST4wwHfgWsAL4BskP5RKILbCOib2R0\nl3QG0ACoB7wnaVRYpbB4m0cCfyf6t30tpjwFeCnczukHnEu0dHBrYEw4118Cm4GeZvZtSTGHr4oW\nqEf4nSAaHfibmRnwrqRGkpqZ2Xa/J5IGEiUJNG58MLe0qf65ZFZWVuHrBx54gNzcXEaMGEGrVq04\n8shoWYdNmzYxd+5cGjZsCMCPP/7I5MmTqVu3Lu+++y7du3dn8uTJpR4jNzd3u+MkM++LIt4XRbwv\nEiPeJOBq4HGglaRVwOdEn1D3OpJSgT7AKWaWL+lRonOtB2SZ2U1hUZ87gK7AccCTQEES0JHowroR\n+EDSy2b2YQnHaQ9cDBxP9O8wn5AEFDCz8ZI6E128nw375YZP4aUZC/yfmf1N0tU7qdc6HHtf4DOi\nRYmOl3Q/UWLyQGk7Sroz1FkPdAnFhxIlMwVWhrLtkgAze5zod4nDW7S0MYur//IVOZdl7lCWnZ3N\nunXruOKKKwDYd999OeWUU2jcuPEOdTMzM3nsscdo3bp1idshSjRKmleQjLwvinhfFPG+SIwy/wJL\nqkF0n/sMSfWAGma2IfGhVZnTgfZEF3CAukT3vn+i6JP1YmBzSBIWAykx+880s3UAkp4HOgM7JAHA\nqcALZrYx1H2xhDq74hSg4Jsbk4C7S6n3r/DvuEHSeuCfoXwxsNPHQpvZcGC4pN8D1wC3Aiqp6s7a\nqVu7JstG99pZlWrjm2++oXbt2jRq1Ii8vDxmzZrFTTfdVGr9//3vfzRt2hRJvP/++2zbto2DDjqo\nEiN2zrmylTknwMy2Ef2hx8x+3MsTAIguZk+Ge/AZZnasmY0E8sNQN0ST4jZDYf/EJlPFL3w7uxDu\n9CK5G+Jpd3PM620x74ufz878naKEYyVwWMy25sDqONup9r766iu6dOlCeno6J5xwAl27dqV37948\n+OCDNG/enJUrV5Kens6AAQMAePbZZ2ndujVt27Zl8ODBTJkyhZBUOudctRHvH/uZkm4ApgI/FhSW\ndt94D/cGMF3S/Wa2JqyX0KAc+3cN++QR3Xe/spR6bwITJY0m+nc4i/Dti900l+g2w2QScMtG0tFm\nVvCgqLOBf4fXLwLXSJoCdALWF58PsCdLT09nwYIFO5QPHjyYwYMH71B+zTXXcM015f6SiHPOVap4\nk4CCC1nsPWYDWlRsOFXPzJZK+iMwI9wKyWf78y7L20TD8C2JJgaWdCsAM5svaSqwEPgCeGv3Ii80\nBPi7pCHAcxXUZqzRko4lGjH4AhgUyl8h+nrgZ0TzIa5IwLGdc85VIBWNcDtXuY499lhbtmxZVYdR\nLfikpyLeF0W8L4p4XxSRlG1mHSqirXifGPirksrN7G8VEYRzzjnnKl+8twNOiHm9L9EM+vmAJwFl\nkHQQ0TyD4k4v+BbBLrY7HLiwWPEzZnbnrrZZrP1HiL5pEGusmU2oiPadc85VvbiSADO7Nva9pIZE\n971dGcKFfmff69/Vdu8EKuSCX0r75ZkH4Zxzbg8U72ODi9tI9HhY55xzzu2h4p0T8E+Kvnteg+gp\nec8kKijnnHPOJV68cwLujXm9BfjCzFYmIB7nnHPOVZJ4bwf0NLM54Weuma2UVNrjaJ1zzjm3B4g3\nCehaQlmPigzEOeecc5Vrp7cDJP2WaBndFpIWxWxqQPR4Wuecc87tocoaCfg70TPtXwz/Lfhpb2Z9\nExybc1VqxYoVdOnShdTUVNLS0hg7diwACxcu5MQTTyQjI4MOHTrw/vvvA3DPPfeQkZFBRkYGrVu3\npmbNmnz77d64vIZzbm+x05EAM1tPtGb8JQCSmhA9LKi+pPpm9mXiQ3SuatSqVYsxY8bQrl07NmzY\nQPv27enatSvDhg3j1ltvpUePHrzyyisMGzaMrKwsbrzxRm688UYA/vnPf3L//fdz4IEHVvFZOOdc\n6eL9iuBZwH3AIcAa4AjgEyAtcaG5iiSpH9DBzMq9tJ2kkUCumd0r6TbgTTObVUrdc4HlZra0rHbz\n8reScvPL5Q2nUuSM7kWzZs1o1qwZAA0aNCA1NZVVq1YhiR9++AGA9evXc8ghh+yw/9NPP80ll1xS\nqTE751x5xfsVwTuAE4FZZna8pC6E0QGXXMzsljKqnAu8BJSZBOxJcnJyWLBgAZ06deKBBx6ge/fu\n3HDDDWzbto133nlnu7obN27ktdde4+GHH66iaJ1zLj7xJgH5ZrZOUg1JNczsX/4VwaohqS8wGNgH\neI9o4uZ64BHgDOA74A/An4HDgevM7MWw+2GSXgOOJFrm+E87Oc5w4FfACuAbIDuUTwReMrNnJY0G\nziZ6dsQM4Pnw/mdhOeYLzOw/xdodCAwEaNz4YG5ps2W3+iNRsrKyCl/n5eUxZMgQBgwYwPz583nw\nwQfp378/P/vZz/jXv/7F+eefz5gxYwrrz549m1atWrFo0aISWi5Zbm7udsdMZt4XRbwvinhfJEZc\nSwlLmkX0CW80cBDRLYETzOzkxIbnYklKJbq4n29m+ZIeBd4FniR6lsOrkl4A6gG9iJ7s+KSZZYTb\nAaOA1kSPff4A6GdmH5ZwnPbARKATUaI4H3gs3A6YSPRJfzYwD2hlZiapkZl9H5sklHU+h7doaTUu\nGrvrHZJAOaN7AZCfn0/v3r3p3r07Q4cOBaBhw4Z8//33SMLMaNiwYeHtAYDzzjuPCy+8kEsvvTTu\n4/kyqUW8L4p4XxTxvihS6UsJA+cAecB1wGVAQ+C2igjAlcvpQHvgA0kAdYkSsp+A10KdxcDmkCQs\nBlJi9p9ZsHKhpOeBzsAOSQBwKvCCmW0MdV8soc4PwCZgvKSXiRKDcqlbuybLwsW2OjIz+vfvT2pq\namECAHDIIYcwZ84cMjMzmT17NkcfXbSMxvr165kzZw6TJ0+uipCdc65c4l1F8EdJRwBHm9mTkvYD\naiY2NFcCEX2y//12hdINVjSksw3YDGBm2yTF/hsXH/bZ2TDQToeIzGyLpI5EicnFwDXAz8s+hT3H\n3LlzmTRpEm3atCEjI1oI8q677mLcuHEMGTKELVu2sO+++/L4448X7vPCCy/QrVs36tWrV1VhO+dc\n3OL9dsCvie7jHggcBRwKPEZ0AXCV5w1guqT7zWyNpAOJHtwUr65hnzyi2ztXllLvTWBiuOdfi+jZ\nEH+JrSCpPrCfmb0i6V3gs7BpQzljqrY6d+5MabfLsrOzSyzv168f/fr1S2BUzjlXceK9HXA10JFo\nIhpm9ml4ZoCrRGa2NEy4myGpBpBP9G8Tr7eBSUBLoomBJd0KwMzmS5oKLAS+AN4qoVoDooRkX6IR\nit+F8inAOEmDgV8UnxjonHOu+og3CdhsZj+F+9CEIeayZxS6CmdmU4GpxYrrx2wfWax+/fDfiUST\n/eI9zp3AnSWU94t527GE7XOJJiQ655yr5uJdQGiOpD8AdSV1BZ4B/pm4sJxzzjmXaPGOBNwM9Cea\nef4b4BVgfKKCcpVD0kFE8wyKO73gWwTOOef2XmWtIni4mX1pZtuAceHH7SXChT6jquNwzjlXNcq6\nHfCPgheSnktwLM4555yrRGUlAYp53SKRgTjnnHOucpWVBFgpr51zzjm3hytrYmBbST8QjQjUDa8J\n783M9k9odM4555xLmJ0mAWbmjwZ2zjnn9lLxPifAOeecc3sZTwKcK8GKFSvo0qULqamppKWlMXZs\ntORxnz59yMjIICMjg5SUlMKFhX766SeuuOIK2rRpQ9u2bX3dc+fcHiHehwUlNUm5BY/fTUDbKcBL\nZtZaUgfgV2Y2WFId4GWgMTAKWE20aFM+cJKZ5SUinoogqR8ww8xWV3Usu6pWrVqMGTOGdu3asWHD\nBtq3b0/Xrl2ZOrXoic3XX389DRs2BGDcuOgRGosXL2bNmjX06NGDDz74gBo1PM92zlVfngRUI2FB\nn4JFfY4HaptZBoCkx4B7zWxCIo4tqaaZba2g5voBHxMlLqXKy99Kys0vV9AhK07O6F40a9aMZs2a\nAdCgQQNSU1NZtWoVxx0XLYtgZkybNo3Zs2cDsHTpUk4/PVpUs0mTJjRq1IgPP/yQjh13WF7BOeeq\nDf+YUk6SbpT0gaRFkv4UylIkfSJpnKQlkmZIqruTNtpL+kjSPGJWAZSUKemlsELjZCBD0kJJvwEu\nAm6R9FQpbWZKelPSC5KWSnosrDSIpG6S5kmaL+mZsAwwknIk3SLpbeBCSS0lzQqxzZd0VHnPWdIv\ngA7AUyH2UvthT5GTk8OCBQvo1KlTYdlbb71F06ZNOfroowFo27Yt06dPZ8uWLXz++edkZ2ezYsWK\nqgrZOefi4iMB5SCpG3A00ep5Al6UdBrwZSi/xMx+LWkacAHRhbwkE4BrzWyOpHuKbzSzNZIGADeY\nWe9w7JOIbhs8u5MQOxKt4PcF8BpwvqQs4I/AGWb2o6SbgKHAbWGfTWbWORzjPWC0mb0QlgiuUd5z\nNrPJkq4Jse+wVLGkgcBAgMaND+aWNlt2cjpVI/Z+fl5eHkOGDGHAgAHMnz+/sPz++++nY8eOhXWP\nOuooZs6cSatWrWjatCmtWrXik08+iXtuQG5urs8jCLwvinhfFPG+SAxPAsqnW/hZEN7XJ7oQfgl8\nbmYLQ3k2kFJSA5IaAo3MbE4omgT0qKD43jez/4bjPA10BjYRJQZzw1LQ+wDzYvaZGuo3AA41sxcA\nzGxTKN/tc45lZo8DjwMc3qKljVlc/X4Fcy7LBCA/P5/evXszaNAghg4dWrh9y5Yt9OnTh+zsbJo3\nb15YXnA7AODkk0/m/PPPL7x9UJasrCwyMzMrJP49nfdFEe+LIt4XiVH9/gJXbwJGmdlftiuMJvdt\njinaCpQ2DC4S9/TF4u1aON5MM7uklH1+jImrJBVxziWqW7smy0b3Ks8ulcbM6N+/P6mpqdslAACz\nZs2iVatW2yUAGzduxMyoV68eM2fOpFatWnEnAM45V1V8TkD5vA5cGXNP/dBw/z5uZvY9sF5S51B0\nWQXG11HSkWEuQB/gbeBd4BRJLUPM+0k6poS4fgBWSjo31KsjaT927Zw3AA0q7KyqwNy5c5k0aRKz\nZ88u/ErgK6+8AsCUKVO45JLtc6o1a9bQrl07UlNTufvuu5k0aVJVhO2cc+XiIwHlYGYzJKUC88LQ\nei7Ql+hTcHlcATwhaSPRRbaizANGA22AN4EXzGxb+Mre0+FrhxDNEVhewv6/BP4i6TairyJeuIvn\nPBF4TFIe1fzrjKXp3LkzZiUP2EycOHGHspSUFJYtW5bgqJxzrmJ5EhCH2GcEmNlYYGwJ1VrH1Lm3\njPaygbYxRSNDeRaQVfx1eN8vjlA3mlmfEo43GzihhPKUYu8/BX5eQr1ynbOZPQf40tPOOVfN+e0A\n55xzLkn5SEACSXoEOKVY8djdeeCPpDZE3yiItdnMOhEzcuCcc86VxZOABDKzq8uuVe42FwMZFd2u\nc8655OO3A5xzzrkk5UmAc845l6Q8CXDOOeeSlCcBzjnnXJLyJMA555xLUp4EOOecc0nKkwDnilmx\nYgVdunQhNTWVtLQ0xo6NHpbYp0+fwnUEUlJSyMgo+qbmokWLOOmkk0hLS6NNmzZs2rSpqsJ3zrm4\n+XMCnCumVq1ajBkzhnbt2rFhwwbat29P165dmTp1amGd66+/noYNGwLR0sJ9+/Zl0qRJtG3blnXr\n1lG7du2qCt855+LmIwFJTFJuBbd3oaQlkrZJ6lCRbVemZs2a0a5dOwAaNGhAamoqq1atKtxuZkyb\nNq1wJcEZM2aQnp5O27bRchAHHXQQNWvWrPzAnXOunHwkwFWkj4Hzgb/EUzkvfyspN7+c2IjKKWd0\nr+3f5+SwYMECOnXqVFj21ltv0bRpU44++mgAli9fjiS6d+/ON998w8UXX8ywYcMqNW7nnNsVngQ4\nACTdCFwE1CFagvhWSSnAq8DbwMnAKuCc0pYGNrNPQls7O85AYCBA48YHc0ubLRV3EhUgKyur8HVe\nXh5DhgxhwIABzJ8/v7D8/vvvp2PHjoV1ly1bxqxZs3jssceoU6cO119/PTVr1qR9+/ZxHzc3N3e7\nYycz74si3hdFvC8Sw5MAh6RuwNFAR0DAi5JOA74M5ZeY2a8lTQMuACbv6rHM7HHgcYDDW7S0MYur\n169gzmWZAOTn59O7d28GDRrE0KFDC7dv2bKFPn36kJ2dTfPmzQH43//+R15eHueccw4AH3zwAdu2\nbSMzMzPu42ZlZZWr/t7M+6KI90UR74vEqF5/gV1V6RZ+FoT39Yku/l8Cn5vZwlCeDaRU1EHr1q7J\nsmLD79WBmdG/f39SU1O3SwAAZs2aRatWrQoTAIDu3bvz5z//mY0bN7LPPvswZ84cfve731V22M45\nV26eBDiIPv2PMrPt7uWH2wGbY4q2AnUrL6yqMXfuXCZNmkSbNm0KvwZ411130bNnT6ZMmVI4IbDA\nAQccwNChQznhhBOQRM+ePenVq/olN845V5wnAQ7gdeB2SU+ZWa6kQ4H8qg6qqnTu3BkzK3HbxIkT\nSyzv27cvffv2TWBUzjlX8fwrgg4zmwH8HZgnaTHwLNCgvO1IOk/SSuAk4GVJr1dspM455yqSjwQk\nMTOrH/N6LDC2hGqtY+rcW0Z7LwAvVFiAzjnnEspHApxzzrkk5SMBrtwkPQKcUqx4rJlNqIp4nHPO\n7RpPAly5mdnVVR2Dc8653ee3A5xzzrkk5UmAc845l6Q8CXDOOeeSlCcBzjnnXJLyJMA555xLUp4E\nOOecc0nKkwDnYqxYsYIuXbqQmppKWloaY8dGD1Hs06cPGRkZZGRkkJKSUriwEMCoUaNo2bIlxx57\nLK+/7k9Kds7tOfw5Ac7FqFWrFmPGjKFdu3Zs2LCB9u3b07VrV6ZOnVpY5/rrr6dhw4YALF26lClT\nprBkyRJWr17NGWecwfLly6lZs2ZVnYJzzsXNk4AkJik3dv2ACmjvHuAs4CfgP8AVZvZ9afXz8reS\ncvPLFXX43ZYzuhfNmjWjWbNmADRo0IDU1FRWrVrFcccdB4CZMW3aNGbPng3A9OnTufjii6lTpw5H\nHnkkLVu25P333+ekk06qsvNwzrl4+e0AV5FmAq3NLB1YDvy+iuPZLTk5OSxYsIBOnToVlr311ls0\nbdqUo48+GoBVq1Zx2GGHFW5v3rw5q1atqvRYnXNuV/hIgANA0o3ARUAd4AUzu1VSCvAq8DZwMrAK\nOMfM8kpqIyxJXOBd4BclHGcgMBCgceODuaXNlgo8i92TlZVV+DovL48hQ4YwYMAA5s+fX1h+//33\n07Fjx8K6K1eu5JNPPil8/9VXX7FkyRIaN25crmPn5uZud/xk5n1RxPuiiPdFYngS4JDUDTga6AgI\neFHSacCXofwSM/u1pGnABcDkOJq9EphavNDMHgceBzi8RUsbs7j6/ArmXJYJQH5+Pr1792bQoEEM\nHTq0cPuWLVvo06cP2dnZNG/eHIB58+YBkJkZ7Ttq1Ci6detW7tsBWVlZhW0kO++LIt4XRbwvEqP6\n/AV2Valb+FkQ3tcnuvh/CXxuZgtDeTaQUlZjkoYDW4Cndlavbu2aLBvdaxdDTgwzo3///qSmpm6X\nAADMmjWLVq1aFSYAAGeffTaXXnopQ4cOZfXq1Xz66ad07NixssN2zrld4kmAg+jT/ygz+8t2hdHt\ngM0xRVuBujttSLoc6A2cbmZWsWEm3ty5c5k0aRJt2rQp/BrgXXfdRc+ePZkyZQqXXHLJdvXT0tK4\n6KKLOO6446hVqxaPPPKIfzPAObfH8CTAAbwO3C7pKTPLlXQokF/eRiSdCdwE/MzMNlZ0kJWhc+fO\nlJa7TJw4scTy4cOHM3z48ARG5ZxzieFJgMPMZkhKBeZJAsgF+hJ98i+Ph4kmFs4M7bxrZoMqMlbn\nnHMVx5OAJBb7jAAzGwuMLaFa65g695bRXsuKi84551yi+XMCnHPOuSTlIwGu3CQ9ApxSrHismU2o\ninicc87tGk8CXLmZ2dVVHYNzzrnd57cDnHPOuSTlSYBzzjmXpDwJcM4555KUJwHOOedckvIkwDnn\nnEtSngQ455xzScqTAOdirFixgi5dupCamkpaWhpjxxY9RPGhhx7i2GOPJS0tjWHDhhWWL1q0iJNO\nOom0tDTatGnDpk2bqiJ055wrN39OgHMxatWqxZgxY2jXrh0bNmygffv2dO3ala+//prp06ezaNEi\n6tSpw5o1awDYsmULffv2ZdKkSbRt25Z169ZRu3btKj4L55yLjycBFUhSP6CDmV2zC/uOBHLN7F5J\ntwFvmtksSacCjxGt6ncScBvQE3jFzG6Mo91cM6sv6RDgQTP7RXljK9behcBIIBXoaGYfhvKDgGeB\nE4CJ8fRBXv5WUm5+eXfCqVA5o3vRrFkzmjVrBkCDBg1ITU1l1apVjBs3jptvvpk6deoA0KRJEwBm\nzJhBeno6bdu2BeCggw6qmuCdc24X+O2AasjMbjGzWeHtZcC9ZpZhZnnAb4B28SQAxdpcvbsJQPAx\ncD7wZrHyTcAI4IYKOEa1kJOTw4IFC+jUqRPLl///9u4/tqryjuP4+7NqmVOjIG4hTidujmCqQRA1\nsUqdP6rgpMb9MJPphsa5uYGiizqXBZPpsP6aS5xOnYowptn8xTRTUUSQTFdlSHXaypREpgEdjok0\ngPLdH+ep91LbhsJtT+n5vJKbe+5zzz3neb597r3fPuec+7SyaNEijjjiCMaNG0dTUxMAra2tSKK+\nvp7Ro0fT2NiYc63NzLaeRwI6IWkSMAWoBp4HfgSsBW4GjgfeB34GNAL7ARdGxNz08n0lPQYMB+ZE\nxJXd7OcK4CzgLeBd4MVUfjfwCLAn8C2gXtLxwO7ArsDzkn4VEfd1ss3hwByyv+1jZeX7A49ERE0a\nsWgAqshmCbw+tfW7wAZgfESs6azOEfFq2l7H8g+BZyV1O5OgpPOA8wCGDt2bXxz8UXer96kFCxZ8\nstzW1sbUqVM599xzWbJkCWvXrqW5uZkZM2bw2muvceqppzJnzhxaWlp48sknufXWWxk0aBAXX3wx\nVVVVjBkzpkf7Xrdu3Rb7LzLHosSxKHEseoeTgA4kjQS+DRwVEZsk/Zbsv/FdgQURcamkB4FfAicA\nBwEzgfYk4HCyL9b1QJOkR9uHzDvsZwxwBnAo2d9hCSkJaBcRd0iqJfvy/nN63bqIGNVNE24CbomI\neyR19xv/NWnfnwWWA5dGxKGSbiRLTH7dzWu3WUTcBtwGsN8BX4nrm/tPF1xxZh0AmzZt4pRTTuH8\n889n2rRpAIwYMYIpU6ZQV1fHsccey3XXXUdNTQ2rVq2ira2NiRMnAtDU1MTmzZupq6vr0b4XLFjQ\n49cMVI5FiWNR4lj0jv7zCdx/HAeMIfsCB9gFWA1spPSfdTOwISUJzcD+Za+fFxH/AZD0AFALfCoJ\nAI4GHoyI9WnduZ2ssy2OAk5Py7OAa7pY7+mI+AD4QNJa4C+pvBk4pEJ16dYuO1fRMmNCX+xqq0UE\n55xzDiNHjvwkAQBoaGhg/vz51NXV0draysaNGxk6dCj19fU0Njayfv16qqureeaZZ7joootybIGZ\n2dZzEvBpAmZGxOVbFEqXRESkh5vJhs2JiM2SyuMYbKnj4619bntszXY3lC1vLnu8mQL3i8WLFzNr\n1iwOPvhgRo3KBlyuvvpqJk+ezOTJk6mpqaG6upqZM2ciicGDBzNt2jTGjh2LJMaPH8+ECf0rsTEz\n60phP+y78RTwsKQbI2K1pCFkx+K31gnpNW1kx90nd7HeQuBuSTPI/g5fB363HfVut5jsMMNsssMY\n1gO1tbWUcr0tzZ49u9PySZMmMWnSpN6slplZr/DVAR1ExD+BnwNPSFoGzAOG9WATz5INwy8F7u/s\nfIC0nyXAfe3rAYu2p95lpgIXSGoC9qjQNj8h6TRJK8kuV3xU0uNlz60AbgC+J2mlpIMqvX8zM6sc\ndfVfj1lvGzFiRLS0tORdjX7BJz2VOBYljkWJY1Ei6cWIOKwS2/JIgJmZWUH5nIBeln5J76lOnjqu\n/SqCbdzuFcA3OxT/KSKu2tZtdtj+zWRXGpS7KSLuqsT2zcwsf04Celn6ou/uuv5t3e5VQEW+8LvY\nfne/MWBmZgOADweYmZkVlJMAMzOzgnISYGZmVlBOAszMzArKSYCZmVlBOQkwMzMrKCcBZmZmBeUk\nwAD/8hMAAAWnSURBVMzMrKCcBJiZmRWUkwAzM7OC8iyClhtJHwCeRjAzFHgv70r0E45FiWNR4liU\njIiI3SuxIc8dYHlqqdR0mDs6SS84FhnHosSxKHEsSiS9UKlt+XCAmZlZQTkJMDMzKygnAZan2/Ku\nQD/iWJQ4FiWORYljUVKxWPjEQDMzs4LySICZmVlBOQkwMzMrKCcBlgtJJ0lqkbRc0mV516cvSFoh\nqVnS0vZLfCQNkTRP0uvpfnAql6TfpPgskzQ639pvH0l3Slot6eWysh63XdLZaf3XJZ2dR1u2Rxdx\nmC7p36lfLJU0vuy5y1McWiTVl5Xv8O8fSftKelrSq5JekTQ1lRexX3QVi97vGxHhm299egOqgH8B\nBwDVwEvAQXnXqw/avQIY2qGsEbgsLV8GXJOWxwN/BQQcCTyfd/23s+3HAKOBl7e17cAQ4I10Pzgt\nD867bRWIw3Tgkk7WPSi9NwYBw9N7pmqgvH+AYcDotLw70JraXMR+0VUser1veCTA8nA4sDwi3oiI\njcC9wMSc65SXicDMtDwTaCgrvycyzwF7ShqWRwUrISIWAms6FPe07fXAvIhYExHvA/OAk3q/9pXT\nRRy6MhG4NyI2RMSbwHKy986AeP9ExDsRsSQtfwC8CuxDMftFV7HoSsX6hpMAy8M+wFtlj1fSfYcf\nKAJ4QtKLks5LZV+IiHcg+yAAPp/KixCjnrZ9IMfkx2mI+8724W8KFAdJ+wOHAs9T8H7RIRbQy33D\nSYDlQZ2UFeFa1aMiYjRwMnCBpGO6WbeoMYKu2z5QY3IL8GVgFPAOcH0qL0QcJO0G3A9cGBH/627V\nTsoGVDw6iUWv9w0nAZaHlcC+ZY+/CLydU136TES8ne5XAw+SDd2tah/mT/er0+pFiFFP2z4gYxIR\nqyLi44jYDNxO1i+gAHGQtDPZl94fIuKBVFzIftFZLPqibzgJsDw0AQdKGi6pGjgDmJtznXqVpF0l\n7d6+DJwIvEzW7vazmc8GHk7Lc4Gz0hnRRwJr24dIB5Cetv1x4ERJg9Ow6ImpbIfW4VyP08j6BWRx\nOEPSIEnDgQOBvzNA3j+SBPweeDUibih7qnD9oqtY9EnfyPusSN+KeSM707eV7EzWK/KuTx+09wCy\nM3VfAl5pbzOwF/AU8Hq6H5LKBdyc4tMMHJZ3G7az/X8kG87cRPbfyjnb0nZgMtlJUMuB7+fdrgrF\nYVZq57L0gT2sbP0rUhxagJPLynf49w9QSzZUvQxYmm7jC9ovuopFr/cN/2ywmZlZQflwgJmZWUE5\nCTAzMysoJwFmZmYF5STAzMysoJwEmJmZFdROeVfAzKzSJH1MdmlVu4aIWJFTdcz6LV8iaGYDjqR1\nEbFbH+5vp4j4qK/2Z1YpPhxgZoUjaZikhWmO9pclHZ3KT5K0RNJLkp5KZUMkPZQmcXlO0iGpfLqk\n2yQ9AdwjqUrStZKa0ro/yLGJZlvFhwPMbCDaRdLStPxmRJzW4fnvAI9HxFWSqoDPSdqb7PfZj4mI\nNyUNSeteCfwjIhokfQ24h2xCF4AxQG1EtKWZIddGxFhJg4DFkp6IbKpXs37JSYCZDURtETGqm+eb\ngDvTpC0PRcRSSXXAwvYv7YhYk9atBU5PZfMl7SVpj/Tc3IhoS8snAodI+kZ6vAfZb7o7CbB+y0mA\nmRVORCxMUzlPAGZJuhb4L51Pu9rd9KwfdljvJxGxQ01eY8XmcwLMrHAkfQlYHRG3k83eNhr4GzAu\nzcpG2eGAhcCZqawOeC86n/f+ceCHaXQBSV9NM0aa9VseCTCzIqoDfippE7AOOCsi3k3H9R+Q9Bmy\neexPAKYDd0laBqynNM1tR3cA+wNL0tSw7wINvdkIs+3lSwTNzMwKyocDzMzMCspJgJmZWUE5CTAz\nMysoJwFmZmYF5STAzMysoJwEmJmZFZSTADMzs4L6P+qDpHMjaMLdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11303ef60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#XG BOOST\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set our parameters for xgboost\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['eta'] = 0.2\n",
    "#params['max_depth'] = 4\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(X_validate, label=y_validate)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "bst = xgb.train(params, d_train, 2000, watchlist, early_stopping_rounds=50, verbose_eval=10)\n",
    "xgb.plot_importance(bst,height=0.2,max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFR fitted\n",
      "The calculated log loss value on the test set using RFR is = 0.718086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def calculate_logloss(y_true, y_pred):\n",
    "    loss_cal = log_loss(y_true, y_pred)\n",
    "    return loss_cal\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "rfr = RandomForestClassifier()\n",
    "rfr.fit(X_train, y_train)\n",
    "print(\"RFR fitted\")\n",
    "\n",
    "y_rfr_predicted = rfr.predict_proba(X_validate)\n",
    "logloss_rfr = calculate_logloss(y_validate, y_rfr_predicted)\n",
    "\n",
    "\n",
    "print (\"The calculated log loss value on the test set using RFR is = %f\" %logloss_rfr)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01280438,  0.01379341,  0.01530613,  0.01142493,  0.00593536,\n",
       "        0.07411743,  0.04070718,  0.04174546,  0.04766713,  0.01285252,\n",
       "        0.0126964 ,  0.0128552 ,  0.01281804,  0.01827881,  0.01298953,\n",
       "        0.01366917,  0.01597836,  0.01286055,  0.01545714,  0.01308489,\n",
       "        0.01402117,  0.01286599,  0.01330257,  0.01322815,  0.01288102,\n",
       "        0.01290483,  0.01332186,  0.01296168,  0.01349285,  0.01403537,\n",
       "        0.01289862,  0.01295864,  0.01279008,  0.01322735,  0.0130327 ,\n",
       "        0.01352071,  0.013005  ,  0.01328356,  0.01319834,  0.01375683,\n",
       "        0.01351864,  0.0128252 ,  0.01280906,  0.01387897,  0.0130979 ,\n",
       "        0.01358168,  0.01705578,  0.01309642,  0.01305185,  0.01319766,\n",
       "        0.01329262,  0.01335211,  0.01296369,  0.01280136,  0.01696524,\n",
       "        0.01267251,  0.01355137,  0.01354483,  0.01317071,  0.03294983,\n",
       "        0.00155523,  0.00154083,  0.00257087,  0.0048247 ,  0.0009191 ,\n",
       "        0.00156888,  0.00461452,  0.00929908])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Word Match with stop words\n",
    "def overlap_no_stops(row,stops=stops):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in row['token_1']:\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in row['token_2']:\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    shared_words = [w for w in q1words.keys() if w in q2words]\n",
    "    return 2*(len(shared_words))/(len(q1words) + len(q2words))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tfidf Word Match with stop words\n",
    "\n",
    "# If a word appears only once, we ignore it completely (likely a typo)\n",
    "# Epsilon defines a smoothing constant, which makes the effect of extremely rare words smaller\n",
    "def get_weight(count, eps=10000, min_count=2):\n",
    "    if count < min_count:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 / (count + eps)\n",
    "\n",
    "\n",
    "question = pd.Series(train_set['clean_q1'].tolist() + train_set['clean_q2'].tolist()).astype(str)\n",
    " \n",
    "words = (\" \".join(question)).lower().split()\n",
    "counts = Counter(words)\n",
    "weights = {word: get_weight(count) for word, count in counts.items()}\n",
    "\n",
    "def tfidf_no_stops(row,stops=stops):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in row['token_1']:\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in row['token_2']:\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    shared_words = [weights.get(w,0) for w in q1words.keys() if w in q2words]\n",
    "    total_weights=[weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n",
    "    return 2*(np.sum(shared_words))/(np.sum(total_weights))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_train['token_1'] = train_set.apply(lambda x: nltk.word_tokenize(x[\"clean_q1\"]), 1)\n",
    "feature_train['token_2'] = train_set.apply(lambda x: nltk.word_tokenize(x[\"clean_q2\"]), 1)\n",
    "\n",
    "feature_validation['token_1'] = validation_set.apply(lambda x: nltk.word_tokenize(x[\"clean_q1\"]), 1)\n",
    "feature_validation['token_2'] = validation_set.apply(lambda x: nltk.word_tokenize(x[\"clean_q2\"]), 1)\n",
    "\n",
    "feature_train[\"overlap_no_stops\"]=feature_train.apply(overlap_no_stops,1)\n",
    "feature_validation[\"overlap_no_stops\"]=feature_validation.apply(overlap_no_stops,1)\n",
    "\n",
    "feature_train[\"tfidf_no_stops\"]=feature_train.apply(tfidf_no_stops,1)\n",
    "feature_validation[\"tfidf_no_stops\"]=feature_validation.apply(tfidf_no_stops,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_train=feature_train.drop(['token_1','token_2'], axis=1)\n",
    "feature_validation=feature_validation.drop(['token_1','token_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = xy_split(feature_train)\n",
    "X_validate, y_validate = xy_split(feature_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_1</th>\n",
       "      <th>len_2</th>\n",
       "      <th>len_diff</th>\n",
       "      <th>len_diff_percent</th>\n",
       "      <th>first_word_match</th>\n",
       "      <th>overlap_percent</th>\n",
       "      <th>spacy_sentence_similarity</th>\n",
       "      <th>edit_distance</th>\n",
       "      <th>token_jaccard</th>\n",
       "      <th>emb_diff_dim_0</th>\n",
       "      <th>...</th>\n",
       "      <th>entity_same</th>\n",
       "      <th>entity_len_same</th>\n",
       "      <th>entity_len_diff</th>\n",
       "      <th>entity_jaccard</th>\n",
       "      <th>chunk_same</th>\n",
       "      <th>chunk_len_same</th>\n",
       "      <th>chunk_len_diff</th>\n",
       "      <th>chunk_jaccard</th>\n",
       "      <th>overlap_no_stops</th>\n",
       "      <th>tfidf_no_stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>True</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.972389</td>\n",
       "      <td>8</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.049052</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.517569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>True</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.967301</td>\n",
       "      <td>2</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.728492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.987928</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.056544</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>False</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.942117</td>\n",
       "      <td>6</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.181837</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.444526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>1.135135</td>\n",
       "      <td>False</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.768640</td>\n",
       "      <td>27</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.298476</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.101850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>True</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.920428</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.060616</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.650369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>True</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.950507</td>\n",
       "      <td>12</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.112551</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.709799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.985282</td>\n",
       "      <td>2</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.052481</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>True</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.935417</td>\n",
       "      <td>6</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.065252</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.450653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>True</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.907508</td>\n",
       "      <td>6</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.008445</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.581714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.889332</td>\n",
       "      <td>8</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.064226</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.799166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>True</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.881663</td>\n",
       "      <td>7</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.218493</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.432192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>True</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.952662</td>\n",
       "      <td>21</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.030991</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.345191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>True</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.896370</td>\n",
       "      <td>5</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.291070</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.501384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>True</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.912079</td>\n",
       "      <td>12</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.121445</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.397865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>True</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.976390</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.035261</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.869859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.894962</td>\n",
       "      <td>12</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.383958</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.456346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.943048</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.020494</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.802748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>True</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.948776</td>\n",
       "      <td>3</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.019359</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.564205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>1.030303</td>\n",
       "      <td>False</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.920888</td>\n",
       "      <td>20</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.019369</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.394399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>True</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.928636</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.135080</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.945502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.899966</td>\n",
       "      <td>19</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.151089</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.341842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.951922</td>\n",
       "      <td>4</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.091843</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.509633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>False</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.823843</td>\n",
       "      <td>14</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.109843</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.123034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>True</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.904652</td>\n",
       "      <td>6</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.663703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.991617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.011395</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>False</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.935415</td>\n",
       "      <td>10</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.036852</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.641221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>False</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.901240</td>\n",
       "      <td>11</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.094543</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.344481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.938232</td>\n",
       "      <td>8</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.059378</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.395964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323402</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.711874</td>\n",
       "      <td>7</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.299703</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.416859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323403</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>False</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.810299</td>\n",
       "      <td>10</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.073593</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.293332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323404</th>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>True</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.969313</td>\n",
       "      <td>12</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.157102</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.588263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323405</th>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>False</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.929258</td>\n",
       "      <td>25</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.029179</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.268919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323406</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>False</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.986970</td>\n",
       "      <td>4</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.053799</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.873672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323407</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>True</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.944603</td>\n",
       "      <td>4</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.083681</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.581097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323408</th>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>False</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.915098</td>\n",
       "      <td>26</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.294903</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.182194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323409</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.952476</td>\n",
       "      <td>3</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.024056</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.456258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323410</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.034514</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.892171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323411</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>False</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.920044</td>\n",
       "      <td>9</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.079296</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.351235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323412</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.959206</td>\n",
       "      <td>6</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.557372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323413</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.889327</td>\n",
       "      <td>8</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.087496</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.235350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323414</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>True</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.924171</td>\n",
       "      <td>7</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.148802</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.340549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323415</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.960372</td>\n",
       "      <td>6</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.052789</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.543546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323416</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>True</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.927026</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.198692</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.671660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323417</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>True</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.949095</td>\n",
       "      <td>2</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.043193</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323418</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>False</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.838673</td>\n",
       "      <td>9</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.092372</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.196058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323419</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.871483</td>\n",
       "      <td>12</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.256891</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.619678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323420</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>False</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.932693</td>\n",
       "      <td>6</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.160807</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.683148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323421</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>True</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.979126</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.058818</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.732527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323422</th>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.871269</td>\n",
       "      <td>20</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.341542</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.122025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323423</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.929399</td>\n",
       "      <td>9</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.458125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323424</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.951460</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.120697</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.704129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323425</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>False</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.945368</td>\n",
       "      <td>6</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.124231</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.673816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323426</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.913128</td>\n",
       "      <td>12</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.183198</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.507798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323427</th>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.963382</td>\n",
       "      <td>29</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.134201</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.334650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323428</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.935922</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.109781</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.572356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323429</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.901656</td>\n",
       "      <td>9</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.186486</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.174895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323430</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.908650</td>\n",
       "      <td>5</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.147005</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.347073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323431</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.914001</td>\n",
       "      <td>6</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.208445</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.215641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323432 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        len_1  len_2  len_diff  len_diff_percent first_word_match  \\\n",
       "0          14     17         3          0.193548             True   \n",
       "1           6      7         1          0.153846             True   \n",
       "2           8      8         0          0.000000            False   \n",
       "3           9     10         1          0.105263            False   \n",
       "4           8     29        21          1.135135            False   \n",
       "5           7      5         2          0.333333             True   \n",
       "6          11     16         5          0.370370             True   \n",
       "7           9      7         2          0.250000            False   \n",
       "8          11      8         3          0.315789             True   \n",
       "9           5     10         5          0.666667             True   \n",
       "10          7     11         4          0.444444            False   \n",
       "11          8     11         3          0.315789             True   \n",
       "12         10     26        16          0.888889             True   \n",
       "13          5      8         3          0.461538             True   \n",
       "14         16     13         3          0.206897             True   \n",
       "15          7      8         1          0.133333             True   \n",
       "16          7     18        11          0.880000             True   \n",
       "17          7      7         0          0.000000             True   \n",
       "18          6      7         1          0.153846             True   \n",
       "19          8     25        17          1.030303            False   \n",
       "20          8      7         1          0.133333             True   \n",
       "21          7     23        16          1.066667            False   \n",
       "22          9      9         0          0.000000            False   \n",
       "23         16     13         3          0.206897            False   \n",
       "24         12     14         2          0.153846             True   \n",
       "25          8      8         0          0.000000             True   \n",
       "26          9      9         0          0.000000             True   \n",
       "27         13     16         3          0.206897            False   \n",
       "28         10     13         3          0.260870            False   \n",
       "29          8     12         4          0.400000            False   \n",
       "...       ...    ...       ...               ...              ...   \n",
       "323402      8      8         0          0.000000            False   \n",
       "323403      6     11         5          0.588235            False   \n",
       "323404     13     21         8          0.470588             True   \n",
       "323405      7     29        22          1.222222            False   \n",
       "323406     12     11         1          0.086957            False   \n",
       "323407      8      7         1          0.133333             True   \n",
       "323408     15     29        14          0.636364            False   \n",
       "323409      8      8         0          0.000000             True   \n",
       "323410     21     21         0          0.000000             True   \n",
       "323411      8     11         3          0.315789            False   \n",
       "323412     15     15         0          0.000000             True   \n",
       "323413      9      9         0          0.000000            False   \n",
       "323414     11     10         1          0.095238             True   \n",
       "323415      9     11         2          0.200000            False   \n",
       "323416      8     13         5          0.476190             True   \n",
       "323417      7      5         2          0.333333             True   \n",
       "323418     11      6         5          0.588235            False   \n",
       "323419     17     17         0          0.000000             True   \n",
       "323420      8     10         2          0.222222            False   \n",
       "323421      6      8         2          0.285714             True   \n",
       "323422     14     21         7          0.400000            False   \n",
       "323423     10     10         0          0.000000            False   \n",
       "323424      6      6         0          0.000000             True   \n",
       "323425     11     12         1          0.086957            False   \n",
       "323426     13     12         1          0.080000            False   \n",
       "323427     24     36        12          0.400000             True   \n",
       "323428      9      9         0          0.000000             True   \n",
       "323429     12      8         4          0.400000            False   \n",
       "323430     11      9         2          0.200000            False   \n",
       "323431      7      9         2          0.250000             True   \n",
       "\n",
       "        overlap_percent  spacy_sentence_similarity  edit_distance  \\\n",
       "0              0.645161                   0.972389              8   \n",
       "1              0.769231                   0.967301              2   \n",
       "2              0.875000                   0.987928              1   \n",
       "3              0.421053                   0.942117              6   \n",
       "4              0.108108                   0.768640             27   \n",
       "5              0.666667                   0.920428              3   \n",
       "6              0.592593                   0.950507             12   \n",
       "7              0.875000                   0.985282              2   \n",
       "8              0.526316                   0.935417              6   \n",
       "9              0.533333                   0.907508              6   \n",
       "10             0.333333                   0.889332              8   \n",
       "11             0.421053                   0.881663              7   \n",
       "12             0.333333                   0.952662             21   \n",
       "13             0.461538                   0.896370              5   \n",
       "14             0.413793                   0.912079             12   \n",
       "15             0.933333                   0.976390              1   \n",
       "16             0.480000                   0.894962             12   \n",
       "17             0.857143                   0.943048              1   \n",
       "18             0.615385                   0.948776              3   \n",
       "19             0.363636                   0.920888             20   \n",
       "20             0.666667                   0.928636              3   \n",
       "21             0.333333                   0.899966             19   \n",
       "22             0.555556                   0.951922              4   \n",
       "23             0.137931                   0.823843             14   \n",
       "24             0.615385                   0.904652              6   \n",
       "25             0.875000                   0.991617              1   \n",
       "26             1.000000                   1.000000              0   \n",
       "27             0.689655                   0.935415             10   \n",
       "28             0.260870                   0.901240             11   \n",
       "29             0.400000                   0.938232              8   \n",
       "...                 ...                        ...            ...   \n",
       "323402         0.250000                   0.711874              7   \n",
       "323403         0.117647                   0.810299             10   \n",
       "323404         0.470588                   0.969313             12   \n",
       "323405         0.222222                   0.929258             25   \n",
       "323406         0.695652                   0.986970              4   \n",
       "323407         0.533333                   0.944603              4   \n",
       "323408         0.136364                   0.915098             26   \n",
       "323409         0.625000                   0.952476              3   \n",
       "323410         0.809524                   1.000000              1   \n",
       "323411         0.210526                   0.920044              9   \n",
       "323412         0.600000                   0.959206              6   \n",
       "323413         0.111111                   0.889327              8   \n",
       "323414         0.476190                   0.924171              7   \n",
       "323415         0.600000                   0.960372              6   \n",
       "323416         0.666667                   0.927026              8   \n",
       "323417         0.833333                   0.949095              2   \n",
       "323418         0.235294                   0.838673              9   \n",
       "323419         0.588235                   0.871483             12   \n",
       "323420         0.555556                   0.932693              6   \n",
       "323421         0.857143                   0.979126              2   \n",
       "323422         0.114286                   0.871269             20   \n",
       "323423         0.300000                   0.929399              9   \n",
       "323424         0.833333                   0.951460              1   \n",
       "323425         0.608696                   0.945368              6   \n",
       "323426         0.320000                   0.913128             12   \n",
       "323427         0.333333                   0.963382             29   \n",
       "323428         0.666667                   0.935922              3   \n",
       "323429         0.400000                   0.901656              9   \n",
       "323430         0.600000                   0.908650              5   \n",
       "323431         0.375000                   0.914001              6   \n",
       "\n",
       "        token_jaccard  emb_diff_dim_0       ...        entity_same  \\\n",
       "0            0.476190        0.049052       ...               True   \n",
       "1            0.625000        0.003280       ...               True   \n",
       "2            0.777778        0.056544       ...              False   \n",
       "3            0.266667        0.181837       ...              False   \n",
       "4            0.064516        0.298476       ...              False   \n",
       "5            0.500000        0.060616       ...               True   \n",
       "6            0.470588        0.112551       ...              False   \n",
       "7            0.777778        0.052481       ...              False   \n",
       "8            0.357143        0.065252       ...              False   \n",
       "9            0.363636        0.008445       ...              False   \n",
       "10           0.200000        0.064226       ...              False   \n",
       "11           0.266667        0.218493       ...              False   \n",
       "12           0.222222        0.030991       ...              False   \n",
       "13           0.300000        0.291070       ...              False   \n",
       "14           0.260870        0.121445       ...              False   \n",
       "15           0.875000        0.035261       ...              False   \n",
       "16           0.333333        0.383958       ...              False   \n",
       "17           0.750000        0.020494       ...              False   \n",
       "18           0.444444        0.019359       ...              False   \n",
       "19           0.250000        0.019369       ...              False   \n",
       "20           0.500000        0.135080       ...              False   \n",
       "21           0.227273        0.151089       ...              False   \n",
       "22           0.384615        0.091843       ...              False   \n",
       "23           0.076923        0.109843       ...              False   \n",
       "24           0.470588        0.008195       ...               True   \n",
       "25           0.777778        0.011395       ...               True   \n",
       "26           1.000000        0.000000       ...               True   \n",
       "27           0.555556        0.036852       ...              False   \n",
       "28           0.150000        0.094543       ...              False   \n",
       "29           0.250000        0.059378       ...              False   \n",
       "...               ...             ...       ...                ...   \n",
       "323402       0.142857        0.299703       ...              False   \n",
       "323403       0.062500        0.073593       ...              False   \n",
       "323404       0.363636        0.157102       ...              False   \n",
       "323405       0.137931        0.029179       ...              False   \n",
       "323406       0.615385        0.053799       ...              False   \n",
       "323407       0.363636        0.083681       ...              False   \n",
       "323408       0.075000        0.294903       ...              False   \n",
       "323409       0.454545        0.024056       ...               True   \n",
       "323410       0.894737        0.034514       ...              False   \n",
       "323411       0.117647        0.079296       ...               True   \n",
       "323412       0.450000        0.047400       ...               True   \n",
       "323413       0.058824        0.087496       ...              False   \n",
       "323414       0.312500        0.148802       ...              False   \n",
       "323415       0.428571        0.052789       ...              False   \n",
       "323416       0.500000        0.198692       ...              False   \n",
       "323417       0.714286        0.043193       ...               True   \n",
       "323418       0.133333        0.092372       ...              False   \n",
       "323419       0.476190        0.256891       ...              False   \n",
       "323420       0.384615        0.160807       ...              False   \n",
       "323421       0.750000        0.058818       ...              False   \n",
       "323422       0.071429        0.341542       ...              False   \n",
       "323423       0.176471        0.008938       ...               True   \n",
       "323424       0.714286        0.120697       ...               True   \n",
       "323425       0.466667        0.124231       ...              False   \n",
       "323426       0.190476        0.183198       ...              False   \n",
       "323427       0.250000        0.134201       ...              False   \n",
       "323428       0.500000        0.109781       ...              False   \n",
       "323429       0.250000        0.186486       ...               True   \n",
       "323430       0.461538        0.147005       ...               True   \n",
       "323431       0.230769        0.208445       ...              False   \n",
       "\n",
       "        entity_len_same  entity_len_diff  entity_jaccard  chunk_same  \\\n",
       "0                  True                0            0.00       False   \n",
       "1                  True                0            0.00       False   \n",
       "2                  True                0            0.00       False   \n",
       "3                  True                0            0.00       False   \n",
       "4                 False                3            0.00       False   \n",
       "5                  True                0            0.00       False   \n",
       "6                 False                2            0.00       False   \n",
       "7                 False                2            0.00       False   \n",
       "8                  True                0            1.00       False   \n",
       "9                 False                1            0.00       False   \n",
       "10                 True                0            0.00       False   \n",
       "11                False                1            0.00       False   \n",
       "12                 True                0            0.00       False   \n",
       "13                 True                0            1.00       False   \n",
       "14                 True                0            0.00       False   \n",
       "15                 True                0            1.00       False   \n",
       "16                False                3            0.00       False   \n",
       "17                False                1            0.50       False   \n",
       "18                 True                0            0.00       False   \n",
       "19                False                1            0.00       False   \n",
       "20                 True                0            0.00       False   \n",
       "21                False                1            0.00       False   \n",
       "22                 True                0            0.00       False   \n",
       "23                False                1            0.00       False   \n",
       "24                 True                0            1.00       False   \n",
       "25                 True                0            0.00        True   \n",
       "26                 True                0            0.00        True   \n",
       "27                False                1            0.00       False   \n",
       "28                 True                0            0.00       False   \n",
       "29                 True                0            0.00       False   \n",
       "...                 ...              ...             ...         ...   \n",
       "323402             True                0            0.00       False   \n",
       "323403             True                0            0.00       False   \n",
       "323404            False                1            0.00       False   \n",
       "323405            False                1            0.00       False   \n",
       "323406             True                0            1.00       False   \n",
       "323407            False                1            0.00       False   \n",
       "323408            False                4            0.00       False   \n",
       "323409             True                0            0.00       False   \n",
       "323410            False                1            0.75       False   \n",
       "323411             True                0            0.00       False   \n",
       "323412             True                0            0.00       False   \n",
       "323413             True                0            0.00       False   \n",
       "323414            False                1            0.00       False   \n",
       "323415            False                1            0.00       False   \n",
       "323416             True                0            1.00       False   \n",
       "323417             True                0            0.00       False   \n",
       "323418            False                1            0.00       False   \n",
       "323419            False                1            0.50       False   \n",
       "323420            False                1            0.00       False   \n",
       "323421            False                1            0.50       False   \n",
       "323422             True                0            0.00       False   \n",
       "323423             True                0            0.00       False   \n",
       "323424             True                0            0.00       False   \n",
       "323425            False                1            0.00       False   \n",
       "323426            False                2            0.00       False   \n",
       "323427            False                2            0.00       False   \n",
       "323428            False                1            0.00       False   \n",
       "323429             True                0            0.00       False   \n",
       "323430             True                0            0.00       False   \n",
       "323431            False                1            0.00       False   \n",
       "\n",
       "        chunk_len_same  chunk_len_diff  chunk_jaccard  overlap_no_stops  \\\n",
       "0                False               2       0.142857          0.533333   \n",
       "1                False               2       0.000000          0.750000   \n",
       "2                False               1       0.500000          1.000000   \n",
       "3                False               2       0.000000          0.545455   \n",
       "4                False               5       0.000000          0.100000   \n",
       "5                False               1       0.500000          0.666667   \n",
       "6                 True               0       0.250000          0.727273   \n",
       "7                 True               0       0.500000          1.000000   \n",
       "8                 True               0       0.200000          0.444444   \n",
       "9                False               1       0.250000          0.571429   \n",
       "10               False               1       0.000000          0.666667   \n",
       "11                True               0       0.200000          0.400000   \n",
       "12               False               2       0.428571          0.375000   \n",
       "13               False               1       0.000000          0.500000   \n",
       "14               False               1       0.000000          0.421053   \n",
       "15                True               0       1.000000          0.857143   \n",
       "16               False               1       0.250000          0.470588   \n",
       "17                True               0       1.000000          0.800000   \n",
       "18                True               0       0.000000          0.571429   \n",
       "19               False               4       0.142857          0.375000   \n",
       "20                True               0       0.000000          0.888889   \n",
       "21               False               4       0.000000          0.428571   \n",
       "22                True               0       0.333333          0.600000   \n",
       "23               False               2       0.000000          0.133333   \n",
       "24                True               0       0.200000          0.666667   \n",
       "25                True               0       1.000000          1.000000   \n",
       "26                True               0       1.000000          1.000000   \n",
       "27               False               1       0.250000          0.631579   \n",
       "28               False               1       0.250000          0.307692   \n",
       "29               False               1       0.000000          0.500000   \n",
       "...                ...             ...            ...               ...   \n",
       "323402           False               1       0.250000          0.444444   \n",
       "323403           False               2       0.000000          0.250000   \n",
       "323404           False               1       0.166667          0.588235   \n",
       "323405           False               3       0.000000          0.272727   \n",
       "323406           False               1       0.750000          0.888889   \n",
       "323407            True               0       0.333333          0.500000   \n",
       "323408           False               3       0.000000          0.160000   \n",
       "323409           False               2       0.000000          0.500000   \n",
       "323410            True               0       0.600000          0.900000   \n",
       "323411            True               0       0.333333          0.333333   \n",
       "323412           False               2       0.500000          0.571429   \n",
       "323413           False               1       0.250000          0.222222   \n",
       "323414           False               1       0.250000          0.333333   \n",
       "323415           False               1       0.000000          0.615385   \n",
       "323416           False               2       0.500000          0.750000   \n",
       "323417            True               0       0.000000          1.000000   \n",
       "323418           False               2       0.000000          0.222222   \n",
       "323419           False               2       0.500000          0.636364   \n",
       "323420           False               1       0.250000          0.666667   \n",
       "323421           False               1       0.500000          0.750000   \n",
       "323422            True               0       0.000000          0.117647   \n",
       "323423           False               1       0.250000          0.500000   \n",
       "323424            True               0       0.000000          0.750000   \n",
       "323425           False               2       0.333333          0.666667   \n",
       "323426            True               0       0.000000          0.500000   \n",
       "323427           False               2       0.272727          0.296296   \n",
       "323428           False               1       0.000000          0.600000   \n",
       "323429           False               1       0.000000          0.181818   \n",
       "323430           False               2       0.500000          0.444444   \n",
       "323431           False               1       0.000000          0.222222   \n",
       "\n",
       "        tfidf_no_stops  \n",
       "0             0.517569  \n",
       "1             0.728492  \n",
       "2             1.000000  \n",
       "3             0.444526  \n",
       "4             0.101850  \n",
       "5             0.650369  \n",
       "6             0.709799  \n",
       "7             1.000000  \n",
       "8             0.450653  \n",
       "9             0.581714  \n",
       "10            0.799166  \n",
       "11            0.432192  \n",
       "12            0.345191  \n",
       "13            0.501384  \n",
       "14            0.397865  \n",
       "15            0.869859  \n",
       "16            0.456346  \n",
       "17            0.802748  \n",
       "18            0.564205  \n",
       "19            0.394399  \n",
       "20            0.945502  \n",
       "21            0.341842  \n",
       "22            0.509633  \n",
       "23            0.123034  \n",
       "24            0.663703  \n",
       "25            1.000000  \n",
       "26            1.000000  \n",
       "27            0.641221  \n",
       "28            0.344481  \n",
       "29            0.395964  \n",
       "...                ...  \n",
       "323402        0.416859  \n",
       "323403        0.293332  \n",
       "323404        0.588263  \n",
       "323405        0.268919  \n",
       "323406        0.873672  \n",
       "323407        0.581097  \n",
       "323408        0.182194  \n",
       "323409        0.456258  \n",
       "323410        0.892171  \n",
       "323411        0.351235  \n",
       "323412        0.557372  \n",
       "323413        0.235350  \n",
       "323414        0.340549  \n",
       "323415        0.543546  \n",
       "323416        0.671660  \n",
       "323417        1.000000  \n",
       "323418        0.196058  \n",
       "323419        0.619678  \n",
       "323420        0.683148  \n",
       "323421        0.732527  \n",
       "323422        0.122025  \n",
       "323423        0.458125  \n",
       "323424        0.704129  \n",
       "323425        0.673816  \n",
       "323426        0.507798  \n",
       "323427        0.334650  \n",
       "323428        0.572356  \n",
       "323429        0.174895  \n",
       "323430        0.347073  \n",
       "323431        0.215641  \n",
       "\n",
       "[323432 rows x 70 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.63697\tvalid-logloss:0.636923\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.493863\tvalid-logloss:0.494321\n",
      "[20]\ttrain-logloss:0.476027\tvalid-logloss:0.478403\n",
      "[30]\ttrain-logloss:0.469588\tvalid-logloss:0.473951\n",
      "[40]\ttrain-logloss:0.463472\tvalid-logloss:0.470273\n",
      "[50]\ttrain-logloss:0.457493\tvalid-logloss:0.46704\n",
      "[60]\ttrain-logloss:0.452409\tvalid-logloss:0.464383\n",
      "[70]\ttrain-logloss:0.448784\tvalid-logloss:0.463064\n",
      "[80]\ttrain-logloss:0.445431\tvalid-logloss:0.462084\n",
      "[90]\ttrain-logloss:0.441746\tvalid-logloss:0.460632\n",
      "[100]\ttrain-logloss:0.438046\tvalid-logloss:0.459366\n",
      "[110]\ttrain-logloss:0.435184\tvalid-logloss:0.458877\n",
      "[120]\ttrain-logloss:0.432426\tvalid-logloss:0.458354\n",
      "[130]\ttrain-logloss:0.42998\tvalid-logloss:0.457899\n",
      "[140]\ttrain-logloss:0.426859\tvalid-logloss:0.456992\n",
      "[150]\ttrain-logloss:0.424647\tvalid-logloss:0.456678\n",
      "[160]\ttrain-logloss:0.422832\tvalid-logloss:0.456437\n",
      "[170]\ttrain-logloss:0.420935\tvalid-logloss:0.456217\n",
      "[180]\ttrain-logloss:0.419362\tvalid-logloss:0.455916\n",
      "[190]\ttrain-logloss:0.417696\tvalid-logloss:0.455648\n",
      "[200]\ttrain-logloss:0.416282\tvalid-logloss:0.455568\n",
      "[210]\ttrain-logloss:0.414863\tvalid-logloss:0.455149\n",
      "[220]\ttrain-logloss:0.413568\tvalid-logloss:0.455072\n",
      "[230]\ttrain-logloss:0.4123\tvalid-logloss:0.45489\n",
      "[240]\ttrain-logloss:0.411217\tvalid-logloss:0.454842\n",
      "[250]\ttrain-logloss:0.41014\tvalid-logloss:0.454857\n",
      "[260]\ttrain-logloss:0.408734\tvalid-logloss:0.45468\n",
      "[270]\ttrain-logloss:0.407268\tvalid-logloss:0.45471\n",
      "[280]\ttrain-logloss:0.406131\tvalid-logloss:0.454675\n",
      "[290]\ttrain-logloss:0.404744\tvalid-logloss:0.45449\n",
      "[300]\ttrain-logloss:0.403425\tvalid-logloss:0.454383\n",
      "[310]\ttrain-logloss:0.40234\tvalid-logloss:0.454272\n",
      "[320]\ttrain-logloss:0.400982\tvalid-logloss:0.454219\n",
      "[330]\ttrain-logloss:0.400021\tvalid-logloss:0.454279\n",
      "[340]\ttrain-logloss:0.39877\tvalid-logloss:0.454079\n",
      "[350]\ttrain-logloss:0.397377\tvalid-logloss:0.454035\n",
      "[360]\ttrain-logloss:0.3964\tvalid-logloss:0.454083\n",
      "[370]\ttrain-logloss:0.395061\tvalid-logloss:0.454148\n",
      "[380]\ttrain-logloss:0.393837\tvalid-logloss:0.454\n",
      "[390]\ttrain-logloss:0.392846\tvalid-logloss:0.454067\n",
      "[400]\ttrain-logloss:0.39204\tvalid-logloss:0.453965\n",
      "[410]\ttrain-logloss:0.390905\tvalid-logloss:0.453996\n",
      "[420]\ttrain-logloss:0.38975\tvalid-logloss:0.453931\n",
      "[430]\ttrain-logloss:0.388568\tvalid-logloss:0.454066\n",
      "[440]\ttrain-logloss:0.387619\tvalid-logloss:0.454088\n",
      "[450]\ttrain-logloss:0.386599\tvalid-logloss:0.454024\n",
      "[460]\ttrain-logloss:0.385475\tvalid-logloss:0.454024\n",
      "[470]\ttrain-logloss:0.384261\tvalid-logloss:0.454022\n",
      "Stopping. Best iteration:\n",
      "[421]\ttrain-logloss:0.389625\tvalid-logloss:0.453926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#XG BOOST\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set our parameters for xgboost\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['eta'] = 0.2\n",
    "#params['max_depth'] = 4\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(X_validate, label=y_validate)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "bst = xgb.train(params, d_train, 2000, watchlist, early_stopping_rounds=50, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fe915da0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAEWCAYAAACKZoWNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XucVfP+x/HXu4tKQ4MpSlKd0G0uHSlUzvSj6CKRgx9+\nFB3XDOeQcpwuB+cUuZVyzSm3yK2j45IkgxPC6OaWUCShSampSdP0+f2x1ozdtOdSza29P8/Ho8fs\n/V3f9V2f757qs77ftfb6ysxwzjnnXGypUdUBOOecc678eYJ3zjnnYpAneOeccy4GeYJ3zjnnYpAn\neOeccy4GeYJ3zjnnYpAneOdc3JF0v6QRVR2HcxVJ/j1451xZSVoBHAzkRxQfaWbf70Gb6cDjZtZ0\nz6LbO0maCnxnZn+r6lhcbPERvHNuV51qZgkRf3Y7uZcHSbWq8vh7QlLNqo7BxS5P8M65ciHpWEnv\nSFovaVE4Mi/YNkjSZ5I2Svpa0qVheX3gFaCJpJzwTxNJUyXdErF/uqTvIt6vkDRM0mJgk6Ra4X7P\nSVojabmkjBJiLWy/oG1J10v6SdJqSf0l9Zb0haSfJf01Yt/Rkp6VND3sz0eSUiO2t5GUGX4On0jq\nV+S490l6WdIm4GLgPOD6sO//CesNl/RV2P6nkk6PaGOgpP9Kul3SurCvvSK2HyhpiqTvw+3/jtjW\nV9LCMLZ3JKWU+Rfs9jqe4J1ze0zSocBLwC3AgcB1wHOSGoZVfgL6AvsDg4C7JP3ezDYBvYDvd2NG\n4H+BPkAisB34D7AIOBQ4EbhG0sllbOsQoG6470jgIeB84GigGzBSUsuI+qcBz4R9nQb8W1JtSbXD\nOGYDjYCrgCckHRWx77nAP4D9gEeBJ4Dbwr6fGtb5KjxuA+DvwOOSGke00RlYCiQBtwEPS1K47TFg\nX6BdGMNdAJJ+D/wLuBQ4CHgAmCmpThk/I7eX8QTvnNtV/w5HgOsjRofnAy+b2ctmtt3MXgM+BHoD\nmNlLZvaVBd4kSIDd9jCOCWa20sxygWOAhmZ2k5ltNbOvCZL0OWVsKw/4h5nlAU8RJM7xZrbRzD4B\nPgEiR7tZZvZsWP9OgpODY8M/CcDYMI65wIsEJyMFXjCzeeHntCVaMGb2jJl9H9aZDiwDOkVU+cbM\nHjKzfOARoDFwcHgS0Au4zMzWmVle+HkD/Al4wMzmm1m+mT0C/BrG7GLQXnvtyjlXZfqb2ZwiZYcD\nf5R0akRZbeANgHAKeRRwJMHAYl9gyR7GsbLI8ZtIWh9RVhN4u4xtrQ2TJUBu+PPHiO25BIl7p2Ob\n2fbw8kGTgm1mtj2i7jcEMwPR4o5K0gXAX4DmYVECwUlHgR8ijr85HLwnEMwo/Gxm66I0ezhwoaSr\nIsr2iYjbxRhP8M658rASeMzM/lR0QzgF/BxwAcHoNS8c+RdMKUf7Ks8mgpOAAodEqRO530pguZkd\nsTvB74bDCl5IqgE0BQouLRwmqUZEkm8GfBGxb9H+7vBe0uEEsw8nAu+aWb6khfz2eZVkJXCgpEQz\nWx9l2z/M7B9laMfFAJ+id86Vh8eBUyWdLKmmpLrhzWtNCUaJdYA1wLZwNN8zYt8fgYMkNYgoWwj0\nDm8YOwS4ppTjvw9sCG+8qxfG0F7SMeXWwx0dLemM8A7+awimut8D5hOcnFwfXpNPB04lmPYvzo9A\n5PX9+gRJfw0ENygC7csSlJmtJrhp8V5JB4QxnBBufgi4TFJnBepL6iNpvzL22e1lPME75/aYma0k\nuPHsrwSJaSUwFKhhZhuBDOBpYB3BTWYzI/b9HHgS+Dq8rt+E4EaxRcAKguv100s5fj5BIk0DlgPZ\nwGSCm9QqwgvA2QT9+T/gjPB691agH8F18GzgXuCCsI/FeRhoW3BPg5l9CtwBvEuQ/JOBebsQ2/8R\n3FPwOcHNjdcAmNmHBNfhJ4ZxfwkM3IV23V7GH3TjnHO7QNJooJWZnV/VsThXEh/BO+ecczHIE7xz\nzjkXg3yK3jnnnItBPoJ3zjnnYpB/D95VmcTERGvVqlVVh1HpNm3aRP369as6jEoXj/2Oxz6D97ui\nZWVlZZtZw9LqeYJ3Vebggw/mww8/rOowKl1mZibp6elVHUali8d+x2Ofwftd0SR9U5Z6PkXvnHPO\nxSBP8M4551wM8gTvnHPOxSBP8M4551wM8gTvnHPOxSBP8M4551wM8gTvnHPOxSBP8M4551wM8gTv\nnHPOxSBP8M4551wM8gTvnHPOxSBP8M4551wM8gTvnHPOxSBP8M4551wM8gTvnHPO7aaVK1fSvXt3\n2rRpw8CBAxk/fvwO22+//XYkkZ2dXViWmZlJWloa7dq14w9/+ENh+fr16znzzDNp3bo1bdq04d13\n392j2Hw9eOecc2431apVizvuuIPf//73vPzyy1xzzTX06NGDtm3bsnLlSl577TWaNWtWWH/9+vVc\nccUVzJo1i2bNmvHTTz8Vbrv66qs55ZRTePbZZ9m6dSubN2/es9j2aO84ISkNaGJmL1d1LEVJesfM\njt+F+pcBm83sUUlTgRfN7Nnd3H8gMNvMvt/VuAFy8/JpPvyl3dl1r3Zt8jYGer/jQjz2GeKn3yvG\n9qFx48Y0btwYgH333Zc2bdqwatUq2rZty5///Gduu+02TjvttMJ9pk2bxhlnnFGY9Bs1agTAhg0b\neOutt5g6dSoA++yzD/vss88exedT9GWTBvSu6iCi2ZXkHta/38we3Z1jSapVZP+BQJPdacs552LN\nDz/8wIIFC+jcuTMzZ87k0EMPJTU1dYc6X3zxBevWrSM9PZ2jjz6aRx8N/jv9+uuvadiwIYMGDaJD\nhw4MHjyYTZs27VE8FTaCl1QfeBpoCtQEbgZuBaYD3cNq55rZl5JOBf4G7AOsBc4zsx8lJQD3AB0B\nA/4OJALtzezP4XH+BLQxs7+UJQYzmy7paOBOIAHIBgaa2WpJmcD8ML5E4OLw/U1APUldgTHAi2Fc\nyQSf4WgzeyEc0fYD9gV+B8wws+vDWE4B/hnGkW1mJ4bx7dROMZ9nO2BK+BnVAAaY2TJJOWaWICk9\n/Hx+JDgheR5YAlwN1AP6m9lXkkYDOWZ2e5H2RwKnhnXfAS41Mws/k3eALsBMSfsBOcCK8PfyhKRc\n4EZgsJmdHrbXA7jczM4ocpxLgEsAkpIaMjJ5W7TuxrSD6wUjnHgTj/2Oxz5D/PQ7MzOz8HVubi5/\n+9vfGDx4MO+88w7Dhg1j3LhxZGZmsmXLFubNm0eDBg345ptvWLp0KXfccQdbt27lyiuvRBKbN28m\nKyuLgQMHMnDgQO655x4uv/xyLrroot2OryKn6E8BvjezPgCSGhAk+A1m1knSBcDdQF/gv8CxYUIZ\nDFwPXAuMAH4xs+SwjQOArcBiSdebWR4wCLi0rDFIqk2QVE8zszWSzgb+ARR8irXC+HoDo8zspDD5\ndTSzIWE7/wTmmtlFkhKB9yXNCfdPAzoAvwJLJd0DbAEeAk4ws+WSDgzr3hitHTOLdtp2GTDezJ6Q\ntA/BiUJRqUAb4Gfga2By2JergauAa4r5nAAmmtlNYf8eI/i9/Cfclmhmfwi3jQYws2clDQGuM7MP\nJQm4Q1JDM1tD8HuZUvQgZvYg8CBAs5at7I4l8XeV6NrkbXi/40M89hnip98rzksHIC8vj759+9Kz\nZ09GjhzJkiVLWLt2LUOGDAEgOzubq666ivfff5/OnTuTmppKr169AJg5cyZ169alR48ejBkzhiuu\nuAKAmjVrMnbsWNLT03c7vor8DSwBbpd0K8F13reDHMCT4fYngbvC102B6ZIaE4xQl4flJwHnFDRo\nZusAJM0F+kr6DKhtZkt2IYb2QHvgtTCemsDqiH2eD39mAc2Labcn0E/SdeH7ukDBXRSvm9kvYZyf\nAocDBwBvmdnysB8/l9LOZ1GO+S5wo6SmwPNmtixKnQ/MbHV47K+A2RGfQ/co9SN1l3Q9wezDgcAn\n/Jbgp5eyL+HJ2WPA+ZKmAMcBF5S0T73aNVk6tk9pTceczMzMwv8Y4kk89jse+wzx1W8z4+KLL6ZN\nmzb0798fgOTk5B1unmvevDkffvghSUlJnHbaaQwZMoRt27axdetW5s+fz5///GcOOeQQDjvsMJYu\nXcpRRx3F66+/Ttu2bfcotgpL8Gb2RTgV3hsYI6kg2VhktfDnPcCdZjYznGoeHZarSP0Ck4G/Ap8T\nZZRYSgwzgE/M7Lhidvs1/JlP8Z+PCKbIl+5QKHWO2D+yjeL6EbWdYvoyTdJ8oA/wqqTBZja3mNgB\ntke8315CX5BUF7iXYJZiZThKrxtRpawXgqYQnBRsAZ4xs9ifo3POxbV58+bx2GOPkZyczIsvvkhC\nQgL//Oc/6d07+m1bbdq04ZRTTiElJYUaNWowePBg2rdvD8A999zDeeedx9atW2nZsiVTphSb3sqk\nIq/BNwF+NrPHJeUQ3JAFcDYwNvxZ8CW/BsCq8PWFEc3MBoYQTi1LOsDM1pnZfEmHAb8HUnYxhrFA\nQ0nHmdm74ZT9kWb2SQnd2QjsF/H+VeAqSVeFI9cOZraghP3fBSZJalEwRR+O4svcjqSWwNdmNiF8\nnQIUTfC7qyCZZ4f3PZwJlOXO+h0+FzP7XtL3BPdT9Cin2Jxzrtrq2rUrZsH4LTMzM+qU+ooVK3Z4\nP3ToUIYOHbpTvbS0ND788MNyi60i76JPJrimvJDgWvMtYXmdcCR6NfDnsGw08IyktwlueitwC3CA\npI8lLWLHaeangXkF0/ZljcHMthIksFvDNhcCpd2J/gbQVtLC8Jr9zUBtgnsBPg7fFyu8Jn0J8Hx4\nzIIp711p52zg47AvrYHduhO+mPjWE9wjsAT4N/BBGXedCtwffi71wrIngJVm9ml5xeecc27XqeDM\no1IOJq0gmAbOLq1uGdp6EbjLzF7f48BcuZE0EVhgZg+XVveoo46ypUtLvToRc4o7y4918djveOwz\neL8rmqQsM+tYWr297nvwkhIlfQHkenKvXiRlEVw6eLyqY3HOuXhXqd9jMLPm5dDGeuDIyDJJBwHR\nkv2JZrZ2T49ZmSSdTPB1wkjLC75fXp2Z2dFVHYNzzrlATHxRMUziaVUdR3kws1cJbr5zzjnndtte\nN0XvnHPOudJ5gnfOOedikCd455xzLgZ5gnfOOedikCd455xzLgZ5gnfOOedikCd456qJ5s2bk5yc\nTFpaGh07Bg+pGjFiBCkpKaSlpdGzZ0++//57AJ544glSUlJISUnh+OOPZ9GiRVUZunOuGvIE71w1\n8sYbb7Bw4cLCBSeGDh3K4sWLWbhwIX379uWmm24CoEWLFrz55pssXryYESNGcMkll1Rl2M65aigm\nHnRTXUhKBM41s3vD9+MIlqp9GfgK2GxmjxbZpznBWvXtw/dPAu2AKWZ2V1XFXhly8/JpPvylyjpc\ntXFt8jYGRvR7xdg+xdbdf//9C19v2rQJSQAcf/xv6yMde+yxfPfddxUQqXNub+YJvnwlAlcQrK0O\ncCnQ0Mx+LX6X30g6BDjezA6voPhKUjR2V8kk0bNnTyRx6aWXFo7Kb7zxRh599FEaNGjAG2+8sdN+\nDz/8ML169arscJ1z1VylriYX6yQ9BZwGLAXWAP9DsATrGKANkGNmt0s6GvgXsBn4L9DLzNpLWgwc\nEe5/lZm9HeUYmcB8gqVzE4GLzextSXWB+4COwDbgL2a2czYI2mgHTAH2IbhMM4BgqdqC2F8Drgdu\nA3oBRrDU7nRJ6cBNwFrgKOAtghMDAQ+HxzfgX9FmICRdQrB0LklJDY8eefdDpX6usebgevBj7m/v\nkw9tAEB2djZJSUmsW7eO6667joyMDFJTUwvrPfHEE2zdupVBgwYVli1YsIC7776bCRMm0KBBg0rr\nw+7IyckhISGhqsOoVPHYZ/B+V7Tu3buXaTU5H8GXr+FAezNLA5CUE/F6dES9KQQJ/M1wGr9AP4Lp\n+tKeq1/LzDpJ6g2MAk4CrgQws2RJrYHZko40sy1R9r8MGG9mT0jaB6gZJfYBBM/3TwWSgA8kvRXu\n3wloC3wDzALOAJYDh0ZcakiMFriZPQg8CNCsZSu7Y0n8/RW8Nnkbkf1ecV76TnUWLVpEXl7eDktP\ntmjRgj59+vDII48AsHjxYiZOnMhrr73GkUceuVMb1U08LiEaj30G73d1EX//u1YxSQ2ARDN7Myx6\njGCUvCueD39mAc3D112BewDM7HNJ3xCsurc4yv7vAjdKago8b2bLCq7tRugKPGlm+cCPkt4EjgE2\nAO+b2ddhf54M674OtJR0D/ASMLu0TtSrXZOlJVx/jlWZmZk7JfVNmzaxfft29ttvPzZt2sTs2bMZ\nOXIky5Yt44gjjgBg5syZtG7dGoBvv/2WM844g8cee2yvSO7OucrnCb7yiWAKe08UXNPP57ff4U4Z\nujhmNk3SfKAP8KqkwcDXUeIstomdm7R1klKBkwlmE84CLiprTPHuxx9/5PTTgxWBt23bxrnnnssp\np5zCgAEDWLp0KTVq1ODwww/n/vvvB+Cmm25i7dq1XHHFFQDUqlWr8M5755wDT/DlbSOwX0kVzGy9\npF8kdTWz/wLnldOx3wrbmivpSKAZwfX0nUhqCXxtZhPC1ynAoiKxvwVcKukR4EDgBGAo0BroJKkF\nwRT92cCDkpKArWb2nKSvgKnl1K+40LJly6jfZX/uueei1p88eTKTJ0+u6LCcc3sxT/DlyMzWSpon\n6WPglRKqDgL+JWkz5bf2+73A/ZKWENxkN7CEu/fPBs6XlAf8ANxkZj8Xif164DiCxG/A9Wb2Q3h9\n/11gLJBMcCIwI3w9RVLBsxVuKKd+Oeec2w2e4MuZmZ0b8XZoRPnoiNdZBDevFRgdlq8A2pfSfnrE\n62zCa/DhzXQDyxjjGII7+0uKHYL4hxatR/B9/rOLlC0Cfl+W4zvnnKt4/iQ755xzLgb5CL6akjQJ\n6FKkeLyZTdmFNk4Gbi1SvNzMTt/duMwsE8jc3f2dc85VDk/w1ZSZXVkObbxK+V3jd845txfxKXrn\nnHMuBnmCd84552KQJ3jnnHMuBnmCd84552KQJ3jnnHMuBnmCd84552KQJ3jnyll+fj4dOnSgb9++\nAEycOJFWrVohiezs7MJ6mZmZNGjQgLS0NNLS0rjpppuqKmTnXAzy78FXMEkrgI7hY2WrrXD99nPN\n7N6qjmVvN378eNq0acOGDRsA6NKlC3379o26TnS3bt148cUXKzlC51w88ARfQRQssF7mJVyrgUTg\nCoJFaypFbl4+zYe/VFmHq3Arxvbhu+++46WXXuLGG2/kzjvvBKBDhw5VHJlzLh75FH0ESX+R9HH4\n5xpJt0q6ImL7aEnXhq+HSvpA0mJJfw/Lmkv6TNK9wEfAYUXa/7ekLEmfSLokojxH0h2SPpL0uqSG\nJcSYGcb1vqQvJHULy+tKmiJpiaQFkrqX0Ea7cP+FYfxHEKwO97uwbJwC48LPYomks8N90yW9JWmG\npE8l3S+phqSakqZG1P/z7vwO9nbXXHMNt912GzVqlO2f1rvvvktqaiq9evXik08+qeDonHPxxEfw\nIUlHEyzj2plg5D0fOB+4m99GtWcBp0jqCRwBdArrzpR0AvAtcBQwyMyuCNuNPMxF4bKs9YAPJD1n\nZmuB+sBHZnatpJHAKGBICeHWMrNOknqHdU8CrgQws+RwSdfZko4MV5kr6jKC59o/IWkfoCYwHGhv\nZmlh3AOANIJV75LCeN8K9+8EtCVYD34WcAawHDjUzNqH+ycW8zlfAlwCkJTUkJHJ20ro5t5lzJgx\n5OXlsXHjRhYuXMjatWvJzMws3L5lyxbmzZtHzZo1yczMZNOmTTz++OPUq1eP9957j5NPPpnHH3+8\n6jpQwXJycnb4POJBPPYZvN/VhSf433QFZpjZJgBJzwPdgEaSmgANgXVm9q2kDKAnsCDcN4Eg4X8L\nfGNm7xVzjAxJBQu9HBbusxbYDkwPyx8Hni8l1oLtWYTLxYbx3wNgZp9L+gY4ElgcZf93gRslNQWe\nN7NlRU5ECtp70szygR8lvQkcA2wA3jezrwEkPRnWfR1oKeke4CVgdrTAzexB4EGAZi1b2R1LYuev\n4P9qA1lZWQwcOJAtW7awYcMGJk+eXJi069atS5cuXfj44493uh6fnp7O/fffT/v27UlKSqqC6Cte\nZmZm1PsQYlk89hm839VF7PzvuueKu17+LHAmcAjwVETdMWb2wA4NSM2BTVEbl9IJRtrHmdlmSZlA\n3WKOaaXE+mv4M5/ffodlvt5vZtMkzQf6AK9KGgx8XTTkkprYuUlbJykVOJlgNuEs4KKS4qhXuyZL\nx/Ypa9h7gT6MGTMGCP6h33777SWOyH/44QcOPvhgJPH++++zfft2DjrooMoK1jkX4/wa/G/eAvpL\n2ldSfeB04G2CpH4OQZJ/Nqz7KnCRpAQASYdKalRK+w0IZgA2h1Pox0ZsqxG2D3Au8N/djP+8MJ4j\ngWbA0mgVJbUEvjazCcBMIAXYCOxXpL2zw2vrDYETgPfDbZ0ktZBUAzgb+K+kJKCGmT0HjAB+vxt9\niEkTJkygadOmfPfdd6SkpDBu3DgAnn32Wdq3b09qaioZGRk89dRTRS/pOOfcbvMRfMjMPpI0ld+S\n2GQzWwAgaT9glZmtDuvOltQGeDf8DzmH4Hp9fgmHmAVcJmkxQeKNnMbfBLSTlAX8QpA0d9W9wP2S\nlgDbgIFm9msxdc8GzpeUB/wA3BTeGzBP0sfAK8D1wHHAIoIR+/Vm9kN4cvIuwU15yQQnAjPC11PC\npA9ww270IWakp6cXTtVlZGSQkZFRuK3gGt2QIUMYMqSkWy2cc273eYKPYGZ3AndGKU+OUjYeGB+l\nmfZF6jWPeNurhGOPIBj5lhZjesTrbMJr8OHNdANL2z+sOwYYE6X83CJFQ8M/RW02s6InIYvwUbtz\nzlUbPkXvnHPOxSAfwVcDZpZQtEzSJKBLkeLxZjalrO1KOhm4tUjxcjM7PVr9sjCzTCBzd/d3zjlX\nOTzBV1NmdmU5tPEqwQ2Bzjnn4oxP0TvnnHMxyBO8c845F4M8wTvnnHMxyBO8c845F4M8wTvnnHMx\nyBO8c845F4M8wTu3G7Zs2UKnTp1ITU2lXbt2jBo1CoBu3bqRlpZGWloaTZo0oX///gCYGRkZGbRq\n1YqLL76Yjz76qCrDd87FAf8evHO7oU6dOsydO5eEhATy8vLo2rUrvXr14u233y6sM2DAAE477TQA\nXnnlFZYtW8ayZcu47777uPzyy5k/f35Vhe+ciwOe4KuIpBVAx/B58jEjXDL3eDObVlrd3Lx8mg9/\nqcJjKm8rxvZBEgkJwQMI8/LyyMvL22EluI0bNzJ37lymTAkePPjCCy9wwQUXIIm2bduyfv16Vq9e\nTePGjaukD8652OdT9JVMgWr1uUsqzxO95gRL3sa8/Px80tLSaNSoET169KBz586F22bMmMGJJ57I\n/vvvD8CqVas47LDDCrc3bdqUVatWVXrMzrn44SP4MpD0F+Ci8O1koDHwjZndG24fDWw0szskDQXO\nAuoAM8xsVDiqfQV4g2AJ1v5F2v83cBhQl+B58w+G5TnAA0B3YB1wjpmtKSbGTGAh0AnYH7jIzN4P\n17a/h2A511rAaDN7QdJAoE94zPrA/0i6Hvg/YDvwipkNl/Q7YBLQENgM/MnMPg+X1t0AdAQOIVhO\n9lmCZWTbSFoIPGJmdxWJ8xLgEoCkpIaMTN5W8odfDRUs9wpw9913k5OTw4gRI2jdujUtWrQAYNKk\nSfTu3buwbnZ2NgsWLGDbtm3k5OSwbt06srKyyMnJqYIeVI2cnJwdPrt4EI99Bu93deEJvhSSjgYG\nAZ0BAfMJ1n6/m2ANdggS+imSegJHECRZATMlnQB8CxwFDDKzK8J2Iw9zUbgeez3gA0nPmdlagsT7\nkZldK2kkMAooaQHx+mZ2fHjMfxEsXXsjMNfMLpKUCLwvaU5Y/zggJTx2L4ITj85mtlnSgWGdB4HL\nzGyZpM5hn/8n3NYY6Aq0BmYCzwLDgevMrG+0AMOTlwcBmrVsZXcs2fv+Cq44L32nsqysLNauXcug\nQYNYu3YtX375JcOGDaNu3boApKamkpSURHp6OpmZmWzatIl+/frF1RR9ZmYm6enpVR1GpYrHPoP3\nu7rY+/53rXxdCUbimwAkPQ90AxpJakIwsl1nZt9KygB6AgvCfRMIEv63BCP+94o5RoakghXeDgv3\nWUswkp4elj8OPF9KrE8CmNlbkvYPE3pPoJ+k68I6dYFm4evXzOzn8PVJwBQz2xy28bOkBOB44JmI\nE5I6Ecf7t5ltBz6VdHApse2kXu2aLB3bZ1d3qxbWrFlD7dq1SUxMJDc3lzlz5jBs2DAAnnnmGfr2\n7VuY3AH69evHxIkTOeecc/j0009p0KBBXCV351zl8wRfOhVT/ixwJsH09FMRdceY2QM7NBBM0W+K\n2riUTpBcjwtHzpkESTgaKyXWotstjGmAmS0tctzORWJSlP1rAOvNLK2Y4/1aZP+4sXr1ai688ELy\n8/PZvn07Z511Fn37BpMWTz31FMOHD9+hfu/evXn55Zdp1aoVZsbTTz9dFWE75+KIJ/jSvQVMlTSW\nIImdTnCdeivwEJAE/CGs+ypws6QnzCxH0qFAXintNyCYAdgsqTVwbMS2GgQnEU8R3Lj231LaOht4\nQ1JX4Bcz+0XSq8BVkq4yM5PUwcwWRNl3NjBS0rSCKfpwFL9c0h/N7BkFw/gUM1tUQgwbgf1KiXOv\nl5KSwoIF0T5Gol6Dk8SkSZMKt3fs2LEiw3POOU/wpTGzj8Ibyt4PiyYXJEhJ+wGrzGx1WHe2pDbA\nu+GUdg7B9fr8Eg4xC7hM0mJgKRA5jb8JaCcpC/iFIIGXZJ2kdwhvsgvLbia4X2BxmKBXADtdHzez\nWZLSgA8lbQVeBv4KnAfcJ+lvQG2Ck42SEvxiYJukRcDUojfZOeecqxye4MvAzO4E7oxSnhylbDww\nPkoz7YvUax7xtlcJxx4BjChjqM+Z2Q1F9s8FLo3S7lRgapGysQR3wUeWLQdOibL/wCLvE8KfecCJ\nZYzXOefaMTpwAAAgAElEQVRcBalW38d2zjnnXPnwEXw1VjAqjiRpEtClSPF4M0uvlKCcc87tFTzB\n72XM7MqqjsE551z151P0zjnnXAza5QQv6QBJKRURjHPOOefKR5kSvKTM8MloBxJ8RWqKpJ3uKnfO\nOedc9VDWEXwDM9sAnEHwONOjCZ6+5pxzzrlqqKwJvpakxgSLqrxYgfE455xzrhyUNcHfRPAY1q/M\n7ANJLYFlFReWc8455/ZEmRK8mT1jZilmdnn4/mszG1CxoTlXPW3ZsoVOnTqRmppKu3btGDVqFABm\nxo033siRRx5JmzZtmDBhwg77ffDBB9SsWZM333yzKsJ2zsWZMn0PXtKRwH3AwWbWPryLvp+Z3VKh\n0TlXDdWpU4e5c+eSkJBAXl4eXbt2pVevXnz22WesXLmSzz//nBo1avDTTz8V7pOfn8+wYcM4+eST\nqzBy51w8KeuDbh4ChgIPAJjZYknTAE/wEcL11881s3tLqJMOXGdmOy34Uk4xvBzGsL4i2i9jDM2B\nF82sfUn1cvPyaT78pUqJqbysGNsHSSQkBA8ZzMvLIy8vD0ncd999TJs2jRo1gomxRo0aFe53zz33\nMGDAAD744IMqids5F3/Keg1+XzN7v0jZtvIOJgYkAldUZQBm1ruyk7ukmpV5vOogPz+ftLQ0GjVq\nRI8ePejcuTNfffUV06dPp2PHjvTq1Ytly4LbVFatWsWMGTO47LLLqjhq51w8KesIPlvS7wADkHQm\nsLrCotp7jQV+J2kh8FpY1ovgc7vFzKZHVpZ0DPAgMAD4EbgHSCb4vYw2sxckDQT6AfsCvwNmmNn1\nxQUgaQXQ0cyyJf0bOAyoS/C8+gfDOqcA/wRqAtlmdqKkhPD4HcN4/25mz0m6DzgGqAc8a2ajIo7z\nL6AnMFHSsvD9ZkpYt17SJcAlAElJDRmZvHedJ0au9X733XeTk5PDiBEjaN26NZs3b2bVqlXcfvvt\nvPXWWwwYMIAJEyYwevRozj77bN5++21++OEHGjduHHXN+FiXk5MTd/2Oxz6D97u6kJmVXim4a/5B\n4HhgHbAcOM/MvqnY8PYukVPTkgYAlxEstZoEfAB0Bo4CriNIsPcAp5vZt5L+CXxqZo+HU/3vAx2A\nPwIjw9e/EqwZ39XMVhYTwwp+S/AHmtnPkuqFx/8DwazNR8AJZrY8os6tQB0zuyZs5wAzWxexvSbw\nOpARXqJZAdxrZreF9RcDV5nZm5LGAb1Km6Jv1rKV1Tgr2sq61deKsX12Kvv73/9O/fr1mTx5MrNm\nzaJ58+aYGYmJifzyyy+0aNGCgn9n2dnZ1K5dmylTptC/f//KDr9KZWZmkp6eXtVhVKp47DN4vyua\npCwz61havVJH8JJqECSMkyTVB2qY2cbyCDLGdQWeNLN84EdJbxKMhDcAbQhOmHqa2fdh/Z5AP0nX\nhe/rAs3C16+b2S8Akj4FDgeiJvgiMiSdHr4+DDgCaAi8Fa7zjpn9HG4/CTinYEczWxe+PCscddcC\nGgNtgcXhtulhTA2ARDMruD38MUpY475Avdo1WRolYVZ3a9asoXbt2iQmJpKbm8ucOXMYNmwY/fv3\nZ+7cuVx00UW8+eabHHnkkQAsX768cN+BAwfSokWLuEvuzrnKV2qCN7PtkoYAT5vZpkqIKVaohG2r\nCRJ4B6AgwQsYYGZLd2hE6kwwci+QT9lOzNIJkvZxZrZZUmZ4TBFeaokS7w7lkloQzDYcE47mp4Zt\nFNhU3L6xbPXq1Vx44YXk5+ezfft2zjrrLPr27UvXrl0577zzuOuuu0hISGDy5MlVHapzLo6V9Rr8\na+HIcjq//aceOfpzgY3AfuHrt4BLJT0CHAicQPBNhNbAeuBiYLakTWaWSfAgoaskXWVmJqmDmS3Y\ng1gaAOvC5N4aODYsfxeYJKlF5BQ9MBsYAhRO0QP7E/y+f5F0MMGoPLPogcxsvaRfJHU1s/8C5+1B\n3NVeSkoKCxbs/KtJTEzkpZdK/lbA1KlTq9U1Oudc7Cprgr8o/Bm5FrkBLcs3nL2bma2VNE/Sx8Ar\nBFPZiwg+q+vN7Icw2WJmP0o6FXhF0kXAzcDdwGJJAlYAu/tVOgNmAZeF18aXAu+Fx10TTrk/H15+\n+QnoQfCVx0lh7PkEN9k9L2kB8AnwNTCvhGMOAv4laTPByYpzzrkqVKYEb2YtKjqQWGFm5xYpGlpk\neybhKNjMvgXaRWy+NEp7U4GpEe+LTfrhjXD7ARvMLI9iroOb2SsEJyCRZTnAhVHqDiymjeZF3mcB\nqRFFo4uL0znnXMUr65PsLohWbmaPlm84bg99AkwOk7tzzrk4VtYp+mMiXtcFTiT4qpUn+CoiaT5Q\np0jxH81sSVXE45xzrnop6xT9VZHvw69FPVYhEbkyMbPOVR2Dc8656qusj6otajPBd6qdc845Vw2V\n9Rr8f/jte841CB528kxFBeWcc865PVPWa/C3R7zeBnxjZt9VQDzOOeecKwdlnaLvbWZvhn/mmdl3\n4bPLnXPOOVcNlTXB94hSVuqzxp1zzjlXNUqcopd0OcH65i3DJ6IV2I+Sn2rmnHPOuSpU2gh+GnAq\nMDP8WfDnaDM7v4Jjc67a2LJlC506dSI1NZV27doxatQoAC6++GJSU1NJSUnhzDPPJCcnp3Cfp59+\nmrZt29KuXTvOPbfoAw6dc65ilTiCD5co/QX4XwBJjQgedJMgKSF81KpzMa9OnTrMnTuXhIQE8vLy\n6Nq1K7169eKuu+5i//33B+Avf/kLEydOZPjw4SxbtowxY8Ywb948DjjgAH766acq7oFzLt6U9Wty\npwJ3Ak0IFic5HPiMHZ+j7naRpIFARzMbIukyYLOZPRqWz45YK760dtKB68ysr6R+QFszG1tM3TSg\niZm9XC6d2AO5efk0H17y6mvVwYqxfZBEQkICAHl5eeTl5SGpMLmbGbm5uQTrBMFDDz3ElVdeyQEH\nHABAo0aNqiZ451zcKutNdrcQLDf6RbjwzIn4NfhyZWb3RzzbfyDBydTutDOzuOQeSgN6707b8S4/\nP5+0tDQaNWpEjx496Nw5eJjgoEGDOOSQQ/j888+56qrgoY9ffPEFX3zxBV26dOHYY49l1qxZVRm6\ncy4OycxKryR9aGYdJS0COpjZdknvm1mnig9x7yXpfCAD2AeYT3DD4gXADcBq4Avg13AEPxrIIVgm\ndiqwCsgFjjOz3Chtn0KwvGw2wboALcMR/EB+mxX4IzCKYPnXX4CTgC+BemH7Y4DlYTv1wuMNMrOl\nYTv9gH2B3wEzzOz6iGP/E6gJZJvZiZLqA/cAyQQzQ6PN7IUocV8CXAKQlNTw6JF3P7SrH2ulSz60\nwQ7vc3JyGDFiBBkZGbRoESy0mJ+fz4QJE2jdujW9evXihhtuoFatWowaNYo1a9aQkZHBlClTSEhI\nICcnp3A2IJ7EY7/jsc/g/a5o3bt3zzKzjqXVK+uDbtZLSgDeBp6Q9BPBA29cMSS1Ac4GuphZnqR7\ngfOBvwNHEyTcN4AFkfuZ2bOShhBMuX9YTNt1gYeA/yFI2NOLCWMkcLKZrZKUaGZbJY0kPAEI29of\nOMHMtkk6iSBxDwj3TwM6AL8CSyXdA2wJj32CmS2XdGBY90ZgrpldJCkReF/SHDPbVKR/DwIPAjRr\n2cruWFLWv4JVZ8V56TuVZWVlsXbtWgYNGlRYVqtWLcaNG8ett95Kamoqxx57LCeddBIAkydP5uCD\nD+aYY44hMzOT9PSd24x18djveOwzeL+ri7L+73oawejuGuA8oAFwU0UFFSNOJEjkH4TXZesBxwOZ\nZrYGQNJ04MjdaLs1sNzMloXtPE44Ki5iHjBV0tPA88W01QB4RNIRBI8jrh2x7fXwRkskfUpw78UB\nwFtmthzAzH4O6/YE+km6LnxfF2hGcK9GVPVq12Tp2D6l9bVaWLNmDbVr1yYxMZHc3FzmzJnD9ddf\nz5dffkmrVq0wM/7zn//QunVrAPr378+TTz7JwIEDyc7O5osvvqBly5ZV3AvnXDwp62pymyQdDhxh\nZo9I2pdgetYVT8AjZnZDYYHUHzi9nNov9dqKmV0mqTPQB1gY3mBX1M3AG2Z2uqTmQGbEtl8jXucT\n/H1RMccWMMDMlpYp+r3M6tWrufDCC8nPz2f79u2cddZZ9OnTh27durFhwwbMjNTUVO677z4ATj75\nZGbPnk3btm2pWbMm48aN46CDDqriXjjn4klZ76L/E8EI8UCC67GHAvcTjFJddK8DL0i6y8x+Cqey\nFwDjJR0EbAD+CCyKsu9GgocJFedzoIWk35nZV4RfYywq3D4fmB9+E+KwKG03ILgeD8HNfaV5F5gk\nqUXBFH04in8VuErSVWZmkjqY2YJS2tprpKSksGDBzt2ZNy/6vaaSuPPOO7nzzjsrOjTnnIuqrHfR\nXwl0IUhKhFPD/r2fEpjZp8DfgNnhUwBfAxoDowmS5ByCm+OimQrcL2mhpHpR2t5CcML1kqT/At8U\n0844SUskfQy8RXAy8QbQNmz7bOA2YIykeZRhVia8vHAJ8Hx402XB9f+bCab3F4fHu7m0tpxzzlWc\nsl6D/zW8QQsASbUowxRxvDOz6ex8A9x7wJQodUdHvH4OeK6UtmcRXIsvWj6V4AQBMzsjyq4/A8cU\nKYu8D2BE0XbC930jXr8CvFLkuLnApSXF7JxzrvKUdQT/pqS/AvUk9SBYC/4/FReWc8455/ZEWRP8\ncGANsIRglPYywfSzq2CSZoTT6ZF/Tq7quJxzzlVvpa0m18zMvjWz7QTffa7+TyWJMWZWXnfdO+ec\niyOljeD/XfBCUonXhJ1zzjlXfZSW4BXx2p/S4Zxzzu0lSkvwVsxr55xzzlVjpX1NLlXSBoKRfL3w\nNeF7M7P9KzQ655xzzu2WEhO8mfnjaJ1zzrm9UFm/Juecc865vYgneOeKsWXLFjp16kRqairt2rVj\n1KhRAEycOJFWrVohiezs7ML6v/zyC6eeemph/SlTdnpgoXPOVRpP8OVI0kBJE3dz39EFS61Kuilc\nmx1J3SR9UvBceknjwvfjythuTviziaRndye2Iu3dLGlxGM9sSU3CckmaIOnLcPvv9/RYVa1OnTrM\nnTuXRYsWsXDhQmbNmsV7771Hly5dmDNnDocffvgO9SdNmkTbtm1ZtGgRmZmZXHvttWzdurWKonfO\nxbuyPoveVSIzGxnx9jzgdjObAiDpUqChmf0adefi2/weOLMcwhtnZiPCWDKAkcBlQC/giPBPZ+C+\n8GexcvPyaT78pXIIqWKsGNuHhIQEAPLy8sjLy0MSHTp0iFpfEhs3bsTMyMnJ4cADD6RWLf8n5pyr\nGj6Cj0LS+ZLeD0epD0iqKSlH0q2SsiTNkdRJUqakryX1i9j9MEmzJC2VNKqU49wY1psDHBVRPlXS\nmZIGA2cBIyU9IWkmUJ9g+dezi2mzhaR3JX0g6eaI8ubhKm8FMw3/lvQfScslDZH0F0kLJL0XLm0b\nlZltiHhbn9++Pnka8KgF3gMSJTUuqf97g/z8fNLS0mjUqBE9evSgc+fiz1mGDBnCZ599RpMmTUhO\nTmb8+PHUqOH/xJxzVcOHF0VIagOcDXQxszxJ9xKMousDmWY2TNIM4BagB9AWeASYGTbRCWgPbAY+\nkPSSmX0Y5ThHA+cAHQh+Dx8BWZF1zGyypK7Ai2b2bLhfjpmlldCF8cB9ZvaopCtLqNc+PHZd4Etg\nmJl1kHQXcAFwd3E7SvpHWOcXoHtYfCiwMqLad2HZ6iL7XkKw3CxJSQ0ZmbythBCrVmZmJgB33303\nOTk5jBgxgtatW9OiRQsguEY/b948GjRoAMCbb75JUlIS06ZN4/vvv2fw4MFMnjyZ+vXr79BuTk5O\nYdvxJB77HY99Bu93deEJfmcnAkcTJGeAesBPwFZgVlhnCcESunmSlgDNI/Z/zczWAkh6HugK7JTg\ngW7ADDPbHNadGaXO7ugCDAhfPwbcWky9N8xsI7BR0i/8tjrgEiClpAOY2Y3AjZJuAIYAo9jxqYeF\nVaPs+yDwIECzlq3sjiXV96/givPSd3iflZXF2rVrGTRoEAB169alS5cuJCUlATBu3DiGDx9Ot27d\nAHj44Ydp2LAhnTp12qGdzMxM0tN3bDsexGO/47HP4P2uLqrv/65VR8AjZnbDDoXSdWZWkLC2A78C\nmNl2SZGfY9GkVtITACvq6YBlaTfyGv72iPfbKfvfi2nASwQJ/jvgsIhtTYHvS9q5Xu2aLB3bp4yH\nqnxr1qyhdu3aJCYmkpuby5w5cxg2bFix9Zs1a8brr79Ot27d+PHHH1m6dCktW/oTnp1zVcMvEO7s\ndeBMSY0AJB0o6fBS9onUI9ynHtAfmFdMvbeA08M74/cDTt2jqH8zj2DqH4JLC+VK0hERb/sBn4ev\nZwIXhHfTHwv8Ymard2pgL7J69Wq6d+9OSkoKxxxzDD169KBv375MmDCBpk2b8t1335GSksLgwYMB\nGDFiBO+88w7JycmceOKJ3HrrrYWje+ecq2w+gi/CzD6V9DdgtqQaQB5Q0rXsov5LMDXeCpgW7fp7\neJyPJE0HFgLfAG/vWeSFrgamSboaqIgVAMdKOopgpP8NwR30AC8DvQmu528GBlXAsStVSkoKCxYs\n2Kk8IyODjIyMncqbNGnC7NmzKyM055wrlSf4KMxsOjC9SHFCxPbRReonhD+nAlN34Tj/AP4RpXxg\ntNeRxyqhzeXAcRFFY8PyFQQ31u0Up5k1j3i9w7Yo7Q8optzYtRMh55xzFcin6J1zzrkY5CP4Cibp\nIILr+kWdWHC3/W62eyPwxyLFz4SzAntM0iSCO/IjjS944I5zzrnqzRN8BQuTeEnfW9/ddqNO75dj\n+z7d7pxzezGfonfOOedikCd455xzLgZ5gnfOOedikCd455xzLgZ5gnfOOedikCd455xzLgZ5gncu\nii1bttCpUydSU1Np164do0aNAmDixIm0atUKSWRnZxfWNzMyMjJo1aoVKSkpfPTRR1UVunPOAf49\neOeiqlOnDnPnziUhIYG8vDy6du1Kr1696NKlC3379t1pSchXXnmFZcuWsWzZMubPn8/ll1/O/Pnz\nqyZ455zDR/BxTVJOObf3R0mfSNouqWN5tl3ZJJGQEDz2Py8vj7y8PCTRoUMHmjdvvlP9F154gQsu\nuABJHHvssaxfv57Vq/fqxfScc3s5H8G78vQxcAbwQFkq5+bl03z4SxUb0W5aMbYP+fn5HH300Xz5\n5ZdceeWVdO7cudj6q1at4rDDDit837RpU1atWkXjxo0rI1znnNuJJ3gHgKShwFlAHWCGmY2S1Bx4\nhWAJ3OOBVcBpZpYbrQ0z+yxsq6TjXAJcApCU1JCRydvKrxPlKDMzE4C7776bnJwcRowYQevWrWnR\nogUQXKOfN28eDRo0ACA7O5sFCxawbVvQn3Xr1pGVlUVOzs6TJDk5OYXtx5N47Hc89hm839WFJ3iH\npJ7AEUAnQMBMSScA34bl/2tmf5L0NDAAeHx3j2VmDwIPAjRr2cruWFI9/wquOC99h/dZWVmsXbuW\nQYOCZe7r1q1Lly5dSEpKAiA1NZWkpKTCa/ObNm2iX79+UUfwmZmZO13Djwfx2O947DN4v6uL6vm/\nq6tsPcM/C8L3CQSJ/VtguZktDMuzgOblddB6tWuydGyf8mquXK1Zs4batWuTmJhIbm4uc+bMYdiw\nYcXW79evHxMnTuScc85h/vz5NGjQwKfnnXNVym+ycxCM2seYWVr4p5WZPRxu+zWiXj5xclK4evVq\nunfvTkpKCscccww9evSgb9++TJgwgaZNm/Ldd9+RkpLC4MGDAejduzctW7akVatW/OlPf+Lee++t\n4h445+JdXPxn7Ur1KnCzpCfMLEfSoUBeVQdVlVJSUliwYMFO5RkZGWRkZOxULolJkyZVRmjOOVcm\nPoJ3mNlsYBrwrqQlwLPAfrvajqTTJX0HHAe8JOnV8o3UOedcWfkIPo6ZWULE6/HA+CjV2kfUub2U\n9mYAM8otQOecc7vNR/DOOedcDPIRvNtlkiYBXYoUjzezKVURj3POuZ15gne7zMyurOoYnHPOlcyn\n6J1zzrkY5AneOeeci0Ge4J1zzrkY5AneOeeci0Ge4J1zzrkY5AneOeeci0Ge4J0rYuXKlXTv3p02\nbdrQrl07xo8PHvC3aNEijjvuOJKTkzn11FPZsGEDAHl5eVx44YUkJyfTpk0bxowZU5XhO+cc4Ane\nuZ3UqlWLO+64g88++4z33nuPSZMm8emnnzJ48GDGjh3LkiVLOP300xk3bhwAzzzzDL/++itLliwh\nKyuLBx54gBUrVlRtJ5xzcc8fdFOOJA0EOprZkN3YdzSQY2a3S7oJeMvM5kjqBtxPsLrbccBNQG/g\nZTMbWoZ2c8wsQVITYIKZnbmrsRVpbxxwKrAV+AoYZGbrJfUAxgL7hNuGmtncktrKzcun+fCX9iSc\ncrdibB8aN25cuJb7fvvtR5s2bVi1ahVLly7lhBNOAKBHjx6cfPLJ3HzzzUhi06ZNbNu2jdzcXPbZ\nZx/233//quyGc875CL46MrORZjYnfHsecHu4TnsucCnw+7Ik9yJtfr+nyT30GtDezFKAL4AbwvJs\n4FQzSwYuBB4rh2NVuRUrVrBgwQI6d+5M+/btmTlzJhCM2leuXAnAmWeeSf369WncuDHNmjXjuuuu\n48ADD6zKsJ1zzkfw0Ug6H8ggGI3OB64AfgEmAScB64C/ArcBzYBrzGxmuPthkmYBLYBpZvb3Eo5z\nI3ABsBJYA2SF5VOBF4FE4CzgZEknESzhWh+YL2mMmU2P0mYLgqVfawGzIsqbAy+aWftwpqE/UJNg\ntbg7wr7+H/Ar0NvMfo4Wc7i0bIH3gDPD8sjF0z8B6kqqY2a/FonvEuASgKSkhoxM3lbcx1MlMjMz\nC1/n5uZy9dVXM3jwYD766CMuu+wybrnlFoYOHUqXLl2oUaMGmZmZLFmyhOzsbJ588kk2btzI1Vdf\nTUJCAk2aNIl6jJycnB2OEy/isd/x2GfwflcXnuCLkNQGOBvoYmZ5ku4lGEXXBzLNbJikGcAtQA+g\nLfAIUJDgOxEkzc3A/7d3/0FWlfcdx98fQQ1xHRWVFvwRJIawgs76K8ZhJUsVf2KVMRmdSkHEMbTa\nokwymhrjJuIUolSJpSZqFSQJ6aAoGGmViAyGFosiuKIDmshA1MlqjSjCGOJ++8d51lzu3r3srrvc\n3bOf18zOPfc5z3nO871nd7/3POfc+6yR9EREPF9iPycDlwEnkh2HtaQE3ywi7pdUS5aYH07bbY+I\nmjIhzAbuiYiHJJX7zvgRad+fA14HboiIEyXdSfam464y2za7EmjxJgO4BHixOLmnmO4F7gU4esix\nMauhe/0Kbr68DshunBs7dixTpkxh2rRpn66fMGECAJs2bWLDhg3U1dWxcOFCJk6cyFlnnQXA448/\nTt++famrqyu5jxUrVrS6Ls96Y9y9MWZw3N1F9/rv2j2cCZxMlpwB+gGNZNeVm8+IG4CP0xuABmBw\nwfbLIuL/ACQtAmqBFgkeOAN4NCJ2pLpLStTpiJFkCRayYfKZrdR7JiI+BD6UtA14PJU3ACfsaSdp\n9OFPwM+KyoenfZ69pzb67duHjTMu2FO1vS4imDx5MtXV1bsl98bGRgYMGEBTUxPTp09nypQpABx9\n9NEsX76c8ePHs2PHDlavXs11111Xqe6bmQG+Bl+KgHnpmndNRHw5IuqBXRERqU4T2VA2EdHE7m+U\ngt0VP2/rus+iLe0Wnl03FTwvjqcFSROBscDlBa8Jko4EHgUmRMRv2tXjbmTVqlXMnz+f5cuXU1NT\nQ01NDUuXLmXBggUMHTqUYcOGMWjQICZNmgTANddcw/bt2xkxYgSnnnoqkyZN4oQT9vgeycysS/kM\nvqWngcWS7oyIRkn9ya59t9WYtM1OsuvcV7ZSbyUwV9IMsuNwIfCTz9DvZqvIhv5/SnZpoVNJOhe4\nAfha8+hDKj8YeAL4TkSs6uz97k21tbUUvG/ZzdSpU1uUVVVVsXDhwq7ulplZu/gMvkhEvAJ8F3hK\n0ktkd40PbEcTvyYbGl8HPFLq+nvaz1qy69frgEeAZz9LvwtMBa6RtAY4qJPaLPSvZG94lklaJ+nH\nqfxa4Fjg5lS+TtKALti/mZm1gc/gS0h3pxffPFZVsL6+qH5VepwLzG3Hfm4DbitRfkWp5cJ9lWnz\nDbLPyzebkco3k91Y16KfETG4YHm3dSXaP7aV8ulkNx6amVk34DN4MzOzHPIZfBeTdCjZdf1iZzbf\nbd/Bdm8CvlFUvDCNCnxmkuaQ3ZFfaHZEPNgZ7ZuZWddygu9iKYmX+9x6R9stObzfie2X+wy9mZl1\ncx6iNzMzyyEneDMzsxxygjczM8shJ3gzM7MccoI3MzPLISd4MzOzHHKCNyuwdetWRo8eTXV1NcOH\nD2f27NkArF+/ntNPP53jjz+eCy+8kA8++GC37bZs2UJVVRV33HFHJbptZtaCE7xZgb59+zJr1ixe\nffVVVq9ezZw5c3jllVe46qqrmDFjBg0NDYwbN47bb799t+2uv/56zjvvvAr12sysJX/RzV4g6Qrg\nlIi4tgPb1gPbI+IOST8AVkbErySdAfwY2EX23fM/AM4HlkbEt9vQ7vaIqJI0CPhRRHy9vX1rpd1v\nAbcDh0fEu+Xq7tz1CYNvfKIzdttpNs+4gIEDs7mFDjzwQKqrq3nzzTfZuHEjo0aNAmDMmDGcc845\n3HrrrQA89thjDBkyhAMOOKBi/TYzK+Yz+B4kIr4XEb9KTy8H7khz1u8Evgmc1JbkXtTmW52Y3I8C\nxgBbOqO9Stu8eTMvvvgip512GiNGjGDJkiUALFy4kK1btwLw0UcfMXPmTG655ZZKdtXMrAW1Nu+1\ntSRpPPCPwH7Ac8DfA9uAOcBZwB+AfwJ+CBwNXBcRS9IZ/Dhgf+AY4OcR8f0y+7kJmABsBd4BXkhn\n8EotidAAAAmsSURBVHOBXwIHp31sA/6bbPrWC4AG4J/TbHjFbR4D/Jxs1Oa/gOvTGfxg4JcRMSL1\n82KgD9nMc7NSrH8LfAycHxHvlen3w8CtwGKyEYsWZ/CSrgauBjjssMNP/t5d97XWXEUcf0Q2w+7O\nnTuZOnUq48ePZ9SoUWzZsoW7776bbdu2MXLkSBYtWsTixYu55557GDZsGKNHj2bu3Ln069ePSy+9\ntOw+tm/fTlVV2UkBc6k3xt0bYwbH3dVGjx79QkScsqd6HqJvI0nVwKXAyIjYJenfyM6iDwBWRMQN\nkh4lmzJ1DHAcMA9Ykpr4ClnS3AGskfREqbniJZ0MXAacSHZ81gIvFNaJiPsl1ZIl5ofTdtsjotx3\n3s8G7omIhySV+575EWnfnwNeB26IiBMl3Un2puOuVl6fvwbejIj1klptPCLuBe4FOHrIsTGroXv9\nCm6+vI5du3YxduxYpkyZwrRp0z5dN2HCBAA2bdrEhg0bqKur4+abb+a5555j3rx5vP/+++yzzz4M\nHz6ca69t/WrMihUrqKur6+pQup3eGHdvjBkcd3fRvf67dm9nAieTJWeAfkAj8EeyM2LIzqA/Tm8A\nGoDBBdsva549TtIioBZokeCBM4BHI2JHqrukRJ2OGAlckpbnAzNbqfdMRHwIfChpG/B4Km8ATii1\ngaTPAzcBZ7enQ/327cPGGRe0Z5MuFxFMnjyZ6urq3ZJ7Y2MjAwYMoKmpienTpzNlyhQAnn322U/r\n1NfXU1VVVTa5m5ntLb4G33YC5qVr3jUR8eWIqAd2xZ+vczSRDWUTEU3s/gaq+FpIuWsjXXXdpC3t\nflyw3FTwvDieQl8ku/SwXtJm4EhgraS/7GA/K2bVqlXMnz+f5cuXU1NTQ01NDUuXLmXBggUMHTqU\nYcOGMWjQICZNmlTprpqZleUz+LZ7Glgs6c6IaJTUn+zad1uNSdvsJLvOfWUr9VYCcyXNIDs+FwI/\n+Qz9braKbOj/p2SXFjpNRDQAA5qfpyRf8hp8d1dbW0tr96VMnTq17Lb19fVd0CMzs47xGXwbRcQr\nwHeBpyS9BCwDBrajiV+TDY2vAx4pdf097Wct8B/N9YBnS9XrgKnANZLWAAd1UptmZtZN+Qy+HdLd\n6cV3qFcVrK8vql+VHucCc9uxn9uA20qUX1FquXBfZdp8g+zz8s1mpPLNZDfWtehnRAwuWN5t3R72\nNXiPlczMrEv5DN7MzCyHfAZfIZIOJbuuX+zM5rvtO9juTcA3iooXplGBz0zSHLI78gvNjogHO6N9\nMzPrHE7wFZKSeLnPrXe03ZLD+53YfrnP0JuZWTfhIXozM7MccoI3MzPLISd4MzOzHHKCNzMzyyEn\neDMzsxxygjczM8shJ3gzM7MccoI3MzPLISd4MzOzHHKCNzMzyyG1Nve1WVeT9CGwsdL9qIDDgHcr\n3YkK6I1x98aYwXF3tS9ExOF7quTvordK2hgRp1S6E3ubpOcdd+/QG2MGx13pfjTzEL2ZmVkOOcGb\nmZnlkBO8VdK9le5AhTju3qM3xgyOu1vwTXZmZmY55DN4MzOzHHKCNzMzyyEneKsISedK2ijpdUk3\nVro/nUnSZkkNktZJej6V9Ze0TNJr6fGQVC5JP0qvw0uSTqps79tO0gOSGiW9XFDW7jglTUz1X5M0\nsRKxtEcrcddLejMd83WSzi9Y950U90ZJ5xSU95i/AUlHSXpG0quSNkiamspzfbzLxN0zjndE+Mc/\ne/UH6AP8BhgC7AesB46rdL86Mb7NwGFFZT8EbkzLNwIz0/L5wH8CAr4KPFfp/rcjzlHAScDLHY0T\n6A/8Nj0ekpYPqXRsHYi7HvhWibrHpd/v/YFj0u99n572NwAMBE5KywcCm1JsuT7eZeLuEcfbZ/BW\nCV8BXo+I30bEH4FfABdVuE9d7SJgXlqeB1xcUP5QZFYDB0saWIkOtldErATeKypub5znAMsi4r2I\n+AOwDDi363vfca3E3ZqLgF9ExMcR8QbwOtnvf4/6G4iItyNibVr+EHgVOIKcH+8ycbemWx1vJ3ir\nhCOArQXPf0f5P5qeJoCnJL0g6epU9hcR8TZk/zSAAak8b69Fe+PMU/zXpuHoB5qHqslh3JIGAycC\nz9GLjndR3NADjrcTvFWCSpTl6fOaIyPiJOA84BpJo8rUzftr0ay1OPMS/z3AF4Ea4G1gVirPVdyS\nqoBHgOsi4oNyVUuU5SnuHnG8neCtEn4HHFXw/EjgrQr1pdNFxFvpsRF4lGx47vfNQ+/psTFVz9tr\n0d44cxF/RPw+Ij6JiCbgPrJjDjmKW9K+ZEnuZxGxKBXn/niXirunHG8neKuENcCXJB0jaT/gMmBJ\nhfvUKSQdIOnA5mXgbOBlsvia7xieCCxOy0uACemu468C25qHPHuo9sb5JHC2pEPSMOfZqaxHKbpv\nYhzZMYcs7ssk7S/pGOBLwP/Sw/4GJAn4d+DViPiXglW5Pt6txd1jjnel71L0T+/8IbvLdhPZnaU3\nVbo/nRjXELI7ZNcDG5pjAw4FngZeS4/9U7mAOel1aABOqXQM7Yh1Adnw5C6yM5TJHYkTuJLsZqTX\ngUmVjquDcc9Pcb1E9o97YEH9m1LcG4HzCsp7zN8AUEs2pPwSsC79nJ/3410m7h5xvP1VtWZmZjnk\nIXozM7MccoI3MzPLISd4MzOzHHKCNzMzyyEneDMzsxzqW+kOmJl1NkmfkH2MqdnFEbG5Qt0xqwh/\nTM7MckfS9oio2ov76xsRf9pb+zNrCw/Rm1mvI2mgpJVpLu+XJZ2Rys+VtFbSeklPp7L+kh5LE4us\nlnRCKq+XdK+kp4CHJPWRdLukNanuNysYopmH6M0sl/pJWpeW34iIcUXr/wZ4MiJuk9QH+Lykw8m+\nV3xURLwhqX+q+33gxYi4WNJfAQ+RTTICcDJQGxE708yB2yLiVEn7A6skPRXZtKFme50TvJnl0c6I\nqCmzfg3wQJpI5LGIWCepDljZnJAjonnO91rgklS2XNKhkg5K65ZExM60fDZwgqSvp+cHkX0XuRO8\nVYQTvJn1OhGxMk3jewEwX9LtwPuUnsKz3FSfHxXV+4eI6LaTp1jv4mvwZtbrSPoC0BgR95HNFnYS\n8D/A19IsYBQM0a8ELk9ldcC7UXou9CeBv0ujAkgammYUNKsIn8GbWW9UB3xb0i5gOzAhIt5J19EX\nSdqHbG7zMUA98KCkl4Ad/Hl61GL3A4OBtWma0XeAi7syCLNy/DE5MzOzHPIQvZmZWQ45wZuZmeWQ\nE7yZmVkOOcGbmZnlkBO8mZlZDjnBm5mZ5ZATvJmZWQ79P9WazpXUUmzRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fe9152e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(bst,height=0.2,max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFR fitted\n",
      "The calculated log loss value on the test set using RFR is = 0.644447\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestClassifier()\n",
    "rfr.fit(X_train, y_train)\n",
    "print(\"RFR fitted\")\n",
    "\n",
    "y_rfr_predicted = rfr.predict_proba(X_validate)\n",
    "logloss_rfr = calculate_logloss(y_validate, y_rfr_predicted)\n",
    "\n",
    "\n",
    "print (\"The calculated log loss value on the test set using RFR is = %f\" %logloss_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2373116507277628\n",
      "0.1912475612920587\n"
     ]
    }
   ],
   "source": [
    "#Oversample negative training sample \n",
    "pos_train = feature_train[feature_train[\"is_duplicate\"] == 1]\n",
    "neg_train = feature_train[feature_train[\"is_duplicate\"] == 0]\n",
    "\n",
    "# Now we oversample the negative class\n",
    "# There is likely a much more elegant way to do this...\n",
    "p = 0.165\n",
    "scale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "print(scale)\n",
    "while scale > 1:\n",
    "    \n",
    "    neg_train = pd.concat([neg_train, neg_train])\n",
    "    scale -=1\n",
    "neg_train = pd.concat([neg_train, neg_train[:int(scale * len(neg_train))]])\n",
    "print(len(pos_train) / (len(pos_train) + len(neg_train)))\n",
    "\n",
    "feature_train = pd.concat([pos_train, neg_train])\n",
    "X_train, y_train = xy_split(feature_train)\n",
    "#y_train = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "del pos_train, neg_train\n",
    "\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = xy_split(feature_train)\n",
    "X_validate, y_validate = xy_split(feature_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.605065\tvalid-logloss:0.640055\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.392595\tvalid-logloss:0.548113\n",
      "[20]\ttrain-logloss:0.372768\tvalid-logloss:0.543956\n",
      "[30]\ttrain-logloss:0.367435\tvalid-logloss:0.540556\n",
      "[40]\ttrain-logloss:0.363046\tvalid-logloss:0.536581\n",
      "[50]\ttrain-logloss:0.358429\tvalid-logloss:0.531969\n",
      "[60]\ttrain-logloss:0.355079\tvalid-logloss:0.529723\n",
      "[70]\ttrain-logloss:0.352118\tvalid-logloss:0.527663\n",
      "[80]\ttrain-logloss:0.348579\tvalid-logloss:0.525079\n",
      "[90]\ttrain-logloss:0.346374\tvalid-logloss:0.52388\n",
      "[100]\ttrain-logloss:0.343913\tvalid-logloss:0.522207\n",
      "[110]\ttrain-logloss:0.34131\tvalid-logloss:0.52086\n",
      "[120]\ttrain-logloss:0.339108\tvalid-logloss:0.520149\n",
      "[130]\ttrain-logloss:0.337077\tvalid-logloss:0.519232\n",
      "[140]\ttrain-logloss:0.335036\tvalid-logloss:0.518371\n",
      "[150]\ttrain-logloss:0.333006\tvalid-logloss:0.5177\n",
      "[160]\ttrain-logloss:0.330771\tvalid-logloss:0.517103\n",
      "[170]\ttrain-logloss:0.329076\tvalid-logloss:0.516608\n",
      "[180]\ttrain-logloss:0.327598\tvalid-logloss:0.516393\n",
      "[190]\ttrain-logloss:0.32605\tvalid-logloss:0.516144\n",
      "[200]\ttrain-logloss:0.324424\tvalid-logloss:0.51559\n",
      "[210]\ttrain-logloss:0.322839\tvalid-logloss:0.515004\n",
      "[220]\ttrain-logloss:0.320762\tvalid-logloss:0.514448\n",
      "[230]\ttrain-logloss:0.31947\tvalid-logloss:0.514221\n",
      "[240]\ttrain-logloss:0.317069\tvalid-logloss:0.51322\n",
      "[250]\ttrain-logloss:0.315188\tvalid-logloss:0.512888\n",
      "[260]\ttrain-logloss:0.313988\tvalid-logloss:0.512707\n",
      "[270]\ttrain-logloss:0.312549\tvalid-logloss:0.512478\n",
      "[280]\ttrain-logloss:0.310507\tvalid-logloss:0.512037\n",
      "[290]\ttrain-logloss:0.308963\tvalid-logloss:0.511889\n",
      "[300]\ttrain-logloss:0.30775\tvalid-logloss:0.511725\n",
      "[310]\ttrain-logloss:0.306057\tvalid-logloss:0.511538\n",
      "[320]\ttrain-logloss:0.305044\tvalid-logloss:0.511402\n",
      "[330]\ttrain-logloss:0.303084\tvalid-logloss:0.51092\n",
      "[340]\ttrain-logloss:0.301039\tvalid-logloss:0.510205\n",
      "[350]\ttrain-logloss:0.299693\tvalid-logloss:0.51007\n",
      "[360]\ttrain-logloss:0.298276\tvalid-logloss:0.509715\n",
      "[370]\ttrain-logloss:0.296545\tvalid-logloss:0.509506\n",
      "[380]\ttrain-logloss:0.295137\tvalid-logloss:0.509497\n",
      "[390]\ttrain-logloss:0.293798\tvalid-logloss:0.509341\n",
      "[400]\ttrain-logloss:0.292375\tvalid-logloss:0.509187\n",
      "[410]\ttrain-logloss:0.291068\tvalid-logloss:0.508972\n",
      "[420]\ttrain-logloss:0.289152\tvalid-logloss:0.508314\n",
      "[430]\ttrain-logloss:0.287485\tvalid-logloss:0.508024\n",
      "[440]\ttrain-logloss:0.286035\tvalid-logloss:0.50785\n",
      "[450]\ttrain-logloss:0.284676\tvalid-logloss:0.507764\n",
      "[460]\ttrain-logloss:0.283383\tvalid-logloss:0.50773\n",
      "[470]\ttrain-logloss:0.281842\tvalid-logloss:0.507347\n",
      "[480]\ttrain-logloss:0.280777\tvalid-logloss:0.507141\n",
      "[490]\ttrain-logloss:0.279785\tvalid-logloss:0.507208\n",
      "[500]\ttrain-logloss:0.278553\tvalid-logloss:0.507024\n",
      "[510]\ttrain-logloss:0.27736\tvalid-logloss:0.506869\n",
      "[520]\ttrain-logloss:0.276228\tvalid-logloss:0.506692\n",
      "[530]\ttrain-logloss:0.2751\tvalid-logloss:0.506732\n",
      "[540]\ttrain-logloss:0.273576\tvalid-logloss:0.506491\n",
      "[550]\ttrain-logloss:0.272565\tvalid-logloss:0.506483\n",
      "[560]\ttrain-logloss:0.271446\tvalid-logloss:0.506336\n",
      "[570]\ttrain-logloss:0.270255\tvalid-logloss:0.506252\n",
      "[580]\ttrain-logloss:0.268974\tvalid-logloss:0.506213\n",
      "[590]\ttrain-logloss:0.267666\tvalid-logloss:0.505923\n",
      "[600]\ttrain-logloss:0.266389\tvalid-logloss:0.505859\n",
      "[610]\ttrain-logloss:0.265013\tvalid-logloss:0.505764\n",
      "[620]\ttrain-logloss:0.263792\tvalid-logloss:0.5055\n",
      "[630]\ttrain-logloss:0.262575\tvalid-logloss:0.505472\n",
      "[640]\ttrain-logloss:0.261456\tvalid-logloss:0.505402\n",
      "[650]\ttrain-logloss:0.260373\tvalid-logloss:0.505261\n",
      "[660]\ttrain-logloss:0.259096\tvalid-logloss:0.505046\n",
      "[670]\ttrain-logloss:0.257789\tvalid-logloss:0.504952\n",
      "[680]\ttrain-logloss:0.256709\tvalid-logloss:0.505027\n",
      "[690]\ttrain-logloss:0.255609\tvalid-logloss:0.504779\n",
      "[700]\ttrain-logloss:0.254705\tvalid-logloss:0.504678\n",
      "[710]\ttrain-logloss:0.253691\tvalid-logloss:0.504563\n",
      "[720]\ttrain-logloss:0.252719\tvalid-logloss:0.504413\n",
      "[730]\ttrain-logloss:0.251591\tvalid-logloss:0.504263\n",
      "[740]\ttrain-logloss:0.250383\tvalid-logloss:0.504129\n",
      "[750]\ttrain-logloss:0.249275\tvalid-logloss:0.504061\n",
      "[760]\ttrain-logloss:0.247986\tvalid-logloss:0.503952\n",
      "[770]\ttrain-logloss:0.247005\tvalid-logloss:0.503931\n",
      "[780]\ttrain-logloss:0.246046\tvalid-logloss:0.50393\n",
      "[790]\ttrain-logloss:0.244949\tvalid-logloss:0.503858\n",
      "[800]\ttrain-logloss:0.243664\tvalid-logloss:0.503607\n",
      "[810]\ttrain-logloss:0.242333\tvalid-logloss:0.503256\n",
      "[820]\ttrain-logloss:0.241202\tvalid-logloss:0.503248\n",
      "[830]\ttrain-logloss:0.239985\tvalid-logloss:0.503084\n",
      "[840]\ttrain-logloss:0.239144\tvalid-logloss:0.503169\n",
      "[850]\ttrain-logloss:0.237861\tvalid-logloss:0.503069\n",
      "[860]\ttrain-logloss:0.236755\tvalid-logloss:0.503058\n",
      "[870]\ttrain-logloss:0.235809\tvalid-logloss:0.502961\n",
      "[880]\ttrain-logloss:0.23467\tvalid-logloss:0.502892\n",
      "[890]\ttrain-logloss:0.233684\tvalid-logloss:0.502768\n",
      "[900]\ttrain-logloss:0.23253\tvalid-logloss:0.502714\n",
      "[910]\ttrain-logloss:0.231389\tvalid-logloss:0.502561\n",
      "[920]\ttrain-logloss:0.230134\tvalid-logloss:0.502378\n",
      "[930]\ttrain-logloss:0.229077\tvalid-logloss:0.502313\n",
      "[940]\ttrain-logloss:0.228246\tvalid-logloss:0.50236\n",
      "[950]\ttrain-logloss:0.227406\tvalid-logloss:0.502324\n",
      "[960]\ttrain-logloss:0.226619\tvalid-logloss:0.502228\n",
      "[970]\ttrain-logloss:0.225736\tvalid-logloss:0.502144\n",
      "[980]\ttrain-logloss:0.224772\tvalid-logloss:0.502012\n",
      "[990]\ttrain-logloss:0.22366\tvalid-logloss:0.501877\n",
      "[1000]\ttrain-logloss:0.222806\tvalid-logloss:0.501785\n",
      "[1010]\ttrain-logloss:0.221853\tvalid-logloss:0.501683\n",
      "[1020]\ttrain-logloss:0.221078\tvalid-logloss:0.50163\n",
      "[1030]\ttrain-logloss:0.220403\tvalid-logloss:0.50162\n",
      "[1040]\ttrain-logloss:0.21952\tvalid-logloss:0.501658\n",
      "[1050]\ttrain-logloss:0.218587\tvalid-logloss:0.50165\n",
      "[1060]\ttrain-logloss:0.21772\tvalid-logloss:0.501666\n",
      "[1070]\ttrain-logloss:0.216827\tvalid-logloss:0.501669\n",
      "Stopping. Best iteration:\n",
      "[1028]\ttrain-logloss:0.220474\tvalid-logloss:0.501553\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fec87160>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAEWCAYAAACKZoWNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fa163278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#XG BOOST\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set our parameters for xgboost\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['eta'] = 0.2\n",
    "#params['max_depth'] = 4\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(X_validate, label=y_validate)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "bst = xgb.train(params, d_train, 2000, watchlist, early_stopping_rounds=50, verbose_eval=10)\n",
    "xgb.plot_importance(bst,height=0.2,max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add single entity feature \n",
    "def upper_str(input_str):\n",
    "    input_str = input_str.upper()\n",
    "    return input_str\n",
    "\n",
    "def upper_dataset(full_dataset):\n",
    "    \"\"\"\n",
    "    Function that cleans the full dataset\n",
    "    \"\"\"\n",
    "    full_dataset[\"clean_q1\"] = full_dataset[\"clean_q1\"].apply(upper_str,1)\n",
    "    full_dataset[\"clean_q2\"] = full_dataset[\"clean_q2\"].apply(upper_str,1)\n",
    "    return full_dataset\n",
    "\n",
    "X_train=upper_dataset(X_train)\n",
    "X_valid=upper_dataset(X_validate)\n",
    "X_test=upper_dataset(X_test)\n",
    "\n",
    "def singleentity(row):\n",
    "    \"\"\"\n",
    "    Function that calculates where there is any entity difference between the two questions\n",
    "    \"\"\"\n",
    "    doc_1 = nlp(row[\"clean_q1\"])\n",
    "    doc_2 = nlp(row[\"clean_q2\"])\n",
    "    if len(doc_1.ents)!=len(doc_2.ents):\n",
    "        return 1\n",
    "    else:\n",
    "        for ent in doc_2.ents:\n",
    "            if ent not in doc_1.ents:\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "X_train[\"singleentity\"]=X_train.apply(singleentity,1)\n",
    "X_valid[\"singleentity\"]=X_valid.apply(singleentity,1)\n",
    "X_test[\"singleentity\"]=X_test.apply(singleentity,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add edit distance feature\n",
    "def distance(row):\n",
    "    \"\"\"\n",
    "    Function that calculates the percentage of edit distance over the average length\n",
    "    \"\"\"\n",
    "    token_1 = nltk.word_tokenize(row[\"clean_q1\"])\n",
    "    token_2 = nltk.word_tokenize(row[\"clean_q2\"])\n",
    "    avg_length = float(len(token_1)+len(token_2))/2\n",
    "    return float(nltk.edit_distance(token_1,token_2))/avg_length\n",
    "\n",
    "X_train[\"Edit_distance\"]=X_train.apply(distance,1)\n",
    "X_valid[\"Edit_distance\"]=X_valid.apply(distance,1)\n",
    "X_test[\"Edit_distance\"]=X_test.apply(distance,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add % of length of the longest common sequence\n",
    "#### May not use as it takes a long time to run ####\n",
    "def lcs(xstr, ystr):\n",
    "    if not xstr or not ystr:\n",
    "        return 0\n",
    "    x, xs, y, ys = xstr[0], xstr[1:], ystr[0], ystr[1:]\n",
    "    if x == y:\n",
    "        return 1 + lcs(xs, ys)\n",
    "    else:\n",
    "        return max(lcs(xstr, ys), lcs(xs, ystr))\n",
    "\n",
    "def longestcommonsequence(row):\n",
    "    token_1 = nltk.word_tokenize(row[\"clean_q1\"])\n",
    "    token_2 = nltk.word_tokenize(row[\"clean_q2\"])\n",
    "    avg_length = float(len(token_1)+len(token_2))/2\n",
    "    return lcs(token_1,token_2)/avg_length  \n",
    "\n",
    "X_train[\"LCS\"]=X_train.apply(longestcommonsequence,1)\n",
    "X_valid[\"LCS\"]=X_valid.apply(longestcommonsequence,1)\n",
    "X_test[\"LCS\"]=X_test.apply(longestcommonsequence,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add similarity score \n",
    "def similarity(row):\n",
    "    sent_1 = nlp(row[\"clean_q1\"])\n",
    "    sent_2 = nlp(row[\"clean_q2\"])\n",
    "    return sent_1.similarity(sent_2)  \n",
    "\n",
    "X_train[\"Similarity\"]=X_train.apply(similarity,1)\n",
    "X_valid[\"Similarity\"]=X_valid.apply(similarity,1)\n",
    "X_test[\"Similarity\"]=X_test.apply(similarity,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#XG BOOST\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set our parameters for xgboost\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['eta'] = 0.02\n",
    "params['max_depth'] = 4\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(X_validate, label=y_validate)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "bst = xgb.train(params, d_train, 2000, watchlist, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert format to support BiMPM\n",
    "def convert_dataset_to_BiMPM(df, name, save_dir=\"../../BiMPM/data\", test=False):\n",
    "    if test:\n",
    "        df[\"is_duplicate\"] = \"-\"\n",
    "    #df[\"non_empty_len_1\"] = df.apply(lambda x: len(x[\"clean_q1\"].replace(\" \",\"\")),1)\n",
    "    #df[\"non_empty_len_2\"] = df.apply(lambda x: len(x[\"clean_q2\"].replace(\" \",\"\")),1)\n",
    "    #df[\"retain\"] = df.apply(lambda x: x[\"non_empty_len_1\"]>0 and x[\"non_empty_len_2\"]>0,1)\n",
    "    wrote_order = [\"is_duplicate\", \"clean_q1\", \"clean_q2\"]\n",
    "    df.to_csv(os.path.join(save_dir, \"bimpm_{0}.csv\".format(name)), columns=wrote_order, sep=\"\\t\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def second_lean(df):\n",
    "    def clean_str(input_str):\n",
    "        return input_str.replace(\"\\n\", \"\")\n",
    "    df[\"clean_q1\"] = df.apply(lambda x: clean_str(x[\"clean_q1\"]) ,1)\n",
    "    df[\"clean_q2\"] = df.apply(lambda x: clean_str(x[\"clean_q2\"]) ,1)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
